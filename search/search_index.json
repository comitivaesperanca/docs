{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Comitiva Esperan\u00e7a \ud83c\udf1f","text":"<p>Organiza\u00e7\u00e3o destinada ao time Comitiva Esperan\u00e7a do programa &lt;/pantanal.dev&gt; \ud83d\ude80, um programa de capacita\u00e7\u00e3o imersiva em tecnologias inovadoras que tem como objetivo capacitar e apresentar oportunidades de trabalho remoto no mercado financeiro nacional \ud83d\udcbc. </p> <p></p>"},{"location":"#sobre-o-desafio-pantanaldev","title":"Sobre o desafio &lt;/pantanal.dev&gt;","text":"<p>Entre os dias 01/04/2023 e 20/05/2023, foi realizado o m\u00f3dulo Arara Azul, focado em Machine Learning, do programa &lt;/pantanal.dev&gt;, um programa desenvolvido por professores da Faculdade de Computa\u00e7\u00e3o da UFMS em parceira com as empresas B3 a bolsa do Brasil, BLK, PDtec e Neoway.  Durante esse per\u00edodo foi proposto a n\u00f3s do time Comitiva Esperan\u00e7a e a outras 9 equipes, o desafio de \"Treinar um algoritmo de Machine Learning capaz de classificar o sentimento de textos de not\u00edcias de Jornais ou Redes Sociais em (Positivo, Neutro ou Negativo)\".   Cabia a cada time definir e construir um produto que resolva um problema real e entregue valor aos seus usu\u00e1rios com esse modelo proposto. </p>"},{"location":"#participantes","title":"Participantes \ud83d\ude4b\u200d\u2640\ufe0f\ud83d\ude4b\u200d\u2642\ufe0f","text":"<p>O time Comitiva Esperan\u00e7a \u00e9 composto por 4 pessoas, de \u00e1reas multidisciplinares. Todos atuam como Data Scientist por\u00e9m exercem o papel prim\u00e1rio descrito abaixo:</p> Vitor Lameir\u00e3o          Engenharia de Software  Product Owner Maycon Felipe Mota          Engenharia de Software  Data Engineer Eduardo Godoy          Engenharia de Software  Backend Engineer Arthur Ramires          Sistema de Informa\u00e7\u00e3o Frontend Engineer Andrezza Andrade          Neoway \ud83d\udc51 Mentora"},{"location":"#repositorios","title":"Reposit\u00f3rios","text":"<p>As aplica\u00e7\u00f5es da plataforma est\u00e1 dividida em quatro reposit\u00f3rios, como:</p> <ul> <li>Dados</li> <li>Backend</li> <li>Frontend</li> <li>Documenta\u00e7\u00e3o</li> </ul>"},{"location":"#tabela-de-versionamento","title":"Tabela de Versionamento","text":"Data Vers\u00e3o Descri\u00e7\u00e3o Autor(es) 03/05/2023 1.0 Cria\u00e7\u00e3o do documento Vitor Lameir\u00e3o"},{"location":"Backend/","title":"Backend","text":""},{"location":"Backend/#domain-driven-design","title":"Domain Driven Design","text":"<p>No projeto da API do \u201cRadar da Soja\u201d foi utilizado padr\u00f5es e conceitos do DDD (Domain Driven Design), possibilitando compreender a fundo o modelo de neg\u00f3cios abordado nesse projeto e o dom\u00ednio do mercado da Soja, permitindo identificar caracter\u00edsticas essenciais das not\u00edcias e entender as regras de neg\u00f3cio relacionadas a elas.</p> <p>Com base nesse conhecimento, foi implementado um modelo de dom\u00ednio que representa as Not\u00edcias, incluindo seus atributos (objetos de valores). Utilizamos tamb\u00e9m o conceito de bounded context, para delimitar em um espa\u00e7o espec\u00edfico as not\u00edcias sobre a soja, isolando suas regras e l\u00f3gica em um contexto bem definido.</p> <p>Com a aplica\u00e7\u00e3o do DDD, foi poss\u00edvel desenvolver um sistema mais estruturado e alinhado com o dom\u00ednio de neg\u00f3cio, facilitando a manuten\u00e7\u00e3o e a evolu\u00e7\u00e3o do projeto ao longo do tempo.</p> <p> </p>"},{"location":"Backend/#web-service","title":"Web Service","text":""},{"location":"Backend/#net-core-c","title":".NET Core C#","text":"<p>Como tecnologia escolhida para o projeto API do Radar da Soja, o .NET Core C# foi escolhido por se tratar de uma linguagem poderosa e vers\u00e1til, pois combina efici\u00eancia e desempenho de linguagens de baixo n\u00edvel com a facilidade de uso e a sintaxe amig\u00e1vel de linguagens de alto n\u00edvel.</p> <p>A plataforma .NET e a linguagem C# s\u00e3o conhecidas por oferecer bom desempenho e escalabilidade. O .NET usa a compila\u00e7\u00e3o just-in-time (JIT) para converter o c\u00f3digo C# em c\u00f3digo de m\u00e1quina altamente otimizado, resultando em execu\u00e7\u00e3o eficiente. Al\u00e9m disso, a plataforma .NET possui recursos avan\u00e7ados para dimensionamento, como o suporte a aplicativos em v\u00e1rias camadas e a capacidade de lidar com grandes volumes de tr\u00e1fego.</p> <p>A Microsoft oferece um ecossistema de produtos e servi\u00e7os amplo e integrado. Ao desenvolver em C#, voc\u00ea pode aproveitar essa integra\u00e7\u00e3o com outros produtos e servi\u00e7os da Microsoft, como o Azure (plataforma de nuvem), o SQL Server (banco de dados), o Office 365 (produtividade), entre outros. Isso permite que voc\u00ea desenvolva aplicativos que se integrem perfeitamente com esses servi\u00e7os e aproveite a sinergia entre eles.</p> <p>Portanto, podemos afirmar que esta tecnologia supre todas nossas necessidades e expectativas para o desenvolvimento desta API, de forma que foi desenvolvida de maneira simples a fim de garantir agilidade no processo de desenvolvimento do projeto.</p>"},{"location":"Backend/#swagger","title":"Swagger","text":"<p>O Swagger consiste em uma ferramenta de aux\u00edlio muito eficaz para proje\u00e7\u00e3o, constru\u00e7\u00e3o, documenta\u00e7\u00e3o e teste de servi\u00e7os de sua API REST.</p> <p>Uma grande vantagem oferecida pelo Swagger \u00e9 a cria\u00e7\u00e3o de documenta\u00e7\u00e3o autom\u00e1tica para nossos servi\u00e7os Web RESTful, que, com base nas anota\u00e7\u00f5es em c\u00f3digo-fonte, a ferramenta Swagger cria a documenta\u00e7\u00e3o detalhada dos endpoints da aplica\u00e7\u00e3o bem como par\u00e2metros, tipos de dados e c\u00f3digos de respotas para suas funcionalidades. Com isso, desenvolvedores e usu\u00e1rios s\u00e3o capazes de entender como utilizar corretamente os servi\u00e7os oferecidos.</p> <p>Atualmente essa ferramenta \u00e9 utilizada em diversos projetos em diversas linguagens, pois oferece um amplo suporte a essa e muitas outras tecnologias e linguagens de programa\u00e7\u00e3o. Al\u00e9m disso, trabalhar com o swagger \u00e9 garantir a padroniza\u00e7\u00e3o e consist\u00eancia de sua API, pois, ao adotar o Swagger, estamos seguindo a abordagem padronizada e consistente para documentar e descrever nossos servi\u00e7os, o que \u00e9 uma excelente vantagem em grandes equipes, mas que tamb\u00e9m se aplica a nosso cen\u00e1rio de desenvolvimento atual.</p> <p>De forma sucinta, o Swagger garanteu uma solu\u00e7\u00e3o comum de documentar servi\u00e7os, garantindo que todos estejam na mesma p\u00e1gina e sigam as mesmas pr\u00e1ticas recomendadas, al\u00e9m de fornecer uma experi\u00eancia interativa na explora\u00e7\u00e3o e teste de APIs.</p>"},{"location":"Backend/#orm-entity-framework-e-code-first","title":"ORM Entity Framework e Code First","text":"<p>Sem d\u00favida, um dos grandes desafios do Pantanal.Dev foi desenvolver um produto de software seguindo conceitos da Engenharia de Software casado com aplica\u00e7\u00e3o de Machine Learning em um tempo extremamente reduzido. Boa parte do tempo de desenvolvimento do projeto foi utilizado para idealizar o produto e construir o modelo de neg\u00f3cio, com isso o desenvolvimento que possuia cronograma curto se mostrou ainda mais apertado em seus prazos.</p> <p>Com isso, tornou-se mais que necess\u00e1rio adotar pr\u00e1ticas e ferramentas que auxiliassem o desenvolvimento \u00e1gil, sendo uma delas o framework ORM Entity Framework, uma poderosa ferramenta capaz de impactar positivamente na produtividade do desenvolvimento da API, fornecendo mapeamentos autom\u00e1ticos de objetos, facilidade na cria\u00e7\u00e3o de tabelas em bancos de dados relacionais atrav\u00e9s de suas Migrations, amplo suporte \u00e0 consultas ao contexto da aplica\u00e7\u00e3o(LINQ) entre outras ferramentas que garantiram que o servi\u00e7o b\u00e1sico da API fosse entregue em tempo para seus usu\u00e1rios.</p> <p>Gra\u00e7as ao Entity Framework ORM, ap\u00f3s o processo de cria\u00e7\u00e3o das Entidades no projeto API, a ferramenta de mapeamento, alinhada aos conceitos de Code Firts, possibilitou a cria\u00e7\u00e3o de tabelas no banco de dados PostgreSQL, poupando horas de trabalho na cria\u00e7\u00e3o manual de tabelas, relacionamentos e defini\u00e7\u00f5es de propriedades dentro da base de dados, tornando-se ineg\u00e1vel o avan\u00e7o em produtividade ao implementarmos primeiramente as classes(entidades) do projeto, para posteriormente serem persistidas ao banco de dados.</p>"},{"location":"Dados/","title":"\ud83d\udc31\u200d\ud83d\udc64 Dados","text":"<p>Com a proposta da solu\u00e7\u00e3o definida, foi necess\u00e1rio definir a arquitetura da plataforma de dados que ir\u00e1 suportar a solu\u00e7\u00e3o, bem como quais dados, modelos e ferramentas ser\u00e3o utilizados para a constru\u00e7\u00e3o da solu\u00e7\u00e3o.</p>"},{"location":"Dados/#fonte-de-dados","title":"Fonte de dados","text":"<p>Foi realizado uma busca de dados abertos que pudessem ser utilizados para a constru\u00e7\u00e3o da solu\u00e7\u00e3o em sites como Kaggle, UCI Machine Learning Repository e Google Dataset Search. Entretanto, n\u00e3o foi encontrado nenhum dataset que atendesse aos requisitos necess\u00e1rios para a constru\u00e7\u00e3o da solu\u00e7\u00e3o, como por exemplo: dados em portugu\u00eas, dados de not\u00edcias referente a Soja, bem como uma classifica\u00e7\u00e3o de sentimento para essas not\u00edcias que tivesse o ponto de vista do produtor rural/trading.</p>"},{"location":"Dados/#cepea-centro-de-estudos-avancados-em-economia-aplicada","title":"CEPEA - Centro de Estudos Avan\u00e7ados em Economia Aplicada","text":"<p>Com a necessidade de treinarmos o modelo utilizando o m\u00e1ximo de fontes que n\u00e3o houvesse vi\u00e9s pol\u00edtico, foi encontrado o site do CEPEA, que \u00e9 um centro de estudos avan\u00e7ados em economia aplicada, que \u00e9 uma institui\u00e7\u00e3o de pesquisa da USP. O CEPEA possui uma p\u00e1gina de boletins di\u00e1rios, chamada Di\u00e1rias do Mercado, que s\u00e3o publica\u00e7\u00f5es di\u00e1rias sobre o mercado de commodities agr\u00edcolas, como soja, milho, caf\u00e9, etc. Esses boletins s\u00e3o publicados diariamente desde 1997.</p>"},{"location":"Dados/#noticias-agricolas","title":"Not\u00edcias Agricolas","text":"<p>Al\u00e9m do CEPEA, foi encontrado o site Not\u00edcias Agricolas, que \u00e9 um portal de not\u00edcias sobre o agroneg\u00f3cio brasileiro. Esse portal possui uma se\u00e7\u00e3o de not\u00edcias sobre soja, que s\u00e3o publicadas diariamente desde 2006. Essa fonte de not\u00edcias \u00e9 interessante pois possui uma vis\u00e3o mais voltada para o produtor rural, diferente do CEPEA que possui uma vis\u00e3o econ\u00f4mica. O Not\u00edcias Agricolas possui um grande volume de not\u00edcias que s\u00e3o de outras fontes como Reuters, o que pode ser interessante para o treinamento do modelo, uma vez que podemos regras para o mercado internacional da commodity.</p>"},{"location":"Dados/#coleta-de-dados","title":"Coleta de dados","text":""},{"location":"Dados/#introducao","title":"Introdu\u00e7\u00e3o","text":"<p>Para realizar a coleta de dados das plataformas acima, foi necess\u00e1rio a utiliza\u00e7\u00e3o da ferramenta Apache Airflow, que \u00e9 uma plataforma de orquestra\u00e7\u00e3o de fluxos de trabalho (workflow) de c\u00f3digo aberto que permite aos usu\u00e1rios programar, agendar e monitorar tarefas em fluxos de trabalho complexos. Essa ferramenta foi escolhida pois suas vantagens permite com que o processo de coleta seja escal\u00e1vel, flex\u00edvel e com monitoramento em tempo real. As tarefas de coleta de dados foram divididas em 3 etapas:</p> <ul> <li>Coleta de dados do CEPEA</li> <li>Coleta de dados do Not\u00edcias Agricolas</li> </ul> <p>Para cada fonte de dados, foi necess\u00e1rio criar uma DAG (Directed Acyclic Graph) que \u00e9 um fluxo de trabalho que define como as tarefas ser\u00e3o executadas, para cada fonte de dados. Essas DAGs foram criadas utilizando a sintaxe de Python, e utilizam bibliotecas como BeautifulSoup, Pandas e Requests para realizar a coleta de dados.</p> <p>O processo de fluxo de dados ficou da seguinte forma:</p> <p></p>"},{"location":"Dados/#processo-de-coleta","title":"Processo de coleta","text":"<p>Para executar a primeira carga de dados completa, foi necess\u00e1rio parametrizar as DAGs para buscar os dados desde 1997, para o CEPEA, e desde 2006, para o Not\u00edcias Agricolas. Ap\u00f3s a execu\u00e7\u00e3o da primeira carga de dados, as DAGs foram parametrizadas para buscar os dados apenas do dia anterior, para que o processo de coleta seja incremental.</p> <p> </p> <p>Na imagem acima, \u00e9 poss\u00edvel visualizar a DAG desenvolvida para a coleta de dados do CEPEA e do Not\u00edcias Agricolas. Essas DAGs s\u00e3o executadas diariamente, e a cada execu\u00e7\u00e3o, os dados do dia anterior s\u00e3o coletados e armazenados localmente, podendo vir a ser carregado a um banco de dados ou a um data lake.</p>"},{"location":"Dados/#analise-exploratoria","title":"An\u00e1lise explorat\u00f3ria","text":"<p>Ao concluir a carga incremental do CEPEA, foi poss\u00edvel obter 7639 not\u00edcias, desde Julho de 2006 at\u00e9 a presente data, conforme o gr\u00e1fico abaixo:</p> Gr\u00e1fico de not\u00edcias coletadas da plataforma CEPEA.  (Fonte: Autores, 2023) <p>J\u00e1 o Not\u00edcias Agricolas, foi poss\u00edvel obter 23.601 not\u00edcias, conforme a imagem abaixo:</p> Gr\u00e1fico de not\u00edcias coletadas do portal Not\u00edcias Agricolas.  (Fonte: Autores, 2023) <p>Para iniciar o tratamento das not\u00edcias, de maneira que fosse poss\u00edvel filtrar apenas as not\u00edcias referentes a soja, foi necess\u00e1rio realizar uma an\u00e1lise explorat\u00f3ria dos dados, para entender quantas not\u00edcias houvesse Soja mencionada, ao menos duas vezes. No Dataset do CEPEA, foi poss\u00edvel encontrar 954 not\u00edcias que tivesse a palavra Soja mencionada ao menos duas vezes, conforme a imagem abaixo:</p> <p>No Dataset do Not\u00edcias Agricolas, foi poss\u00edvel encontrar 3.358 not\u00edcias que tivesse a palavra Soja mencionada ao menos duas vezes, conforme a imagem abaixo:</p> Gr\u00e1fico de not\u00edcias que mencionam a palavra Soja.  (Fonte: Autores, 2023)"},{"location":"Dados/#rotulacao-dos-dados","title":"Rotula\u00e7\u00e3o dos dados","text":"<p>Para realizar a rotula\u00e7\u00e3o dos dados, foi utilizado a ferramenta Label Studio, que \u00e9 uma plataforma de marca\u00e7\u00e3o de dados (data labeling) de c\u00f3digo aberto que permite criar tarefas de marca\u00e7\u00e3o de forma simples e escal\u00e1vel.  Conforme o curto prazo para a entrega do projeto, foi necess\u00e1rio realizar a rotula\u00e7\u00e3o dos dados manualmente, por\u00e9m, para uma entrega futura, \u00e9 poss\u00edvel utilizar t\u00e9cnicas de NLP para realizar a rotula\u00e7\u00e3o dos dados de maneira autom\u00e1tica, como por exemplo, utilizando o Spacy.</p> <p>Devido ao grande volume, a equipe optou por classificar apenas as not\u00edcias do CEPEA, que possu\u00eda um volume menor de dados, e que possu\u00eda uma vis\u00e3o mais econ\u00f4mica, diferente do Not\u00edcias Agricolas, que pode possuir not\u00edcias com vi\u00e9s pol\u00edtico.</p> <p>Foi realizado o deployment da ferramenta Label Studio utilizando o servi\u00e7o de Kubernetes da Azure, e a rotula\u00e7\u00e3o dos dados foi realizada por 4 pessoas do time, conforme a imagem abaixo:  Imagens da plataforma Label Studio.  (Fonte: Autores, 2023)</p>"},{"location":"Dados/#criacao-do-modelo","title":"Cria\u00e7\u00e3o do modelo","text":"<p>Ap\u00f3s a rotula\u00e7\u00e3o dos dados, foi necess\u00e1rio realizar o treinamento do modelo de Machine Learning, para que fosse poss\u00edvel criar o Motor de Classifica\u00e7\u00e3o do Radar da Soja, que \u00e9 o respons\u00e1vel por classificar as not\u00edcias em Positivo, Neutro ou Negativo. Com a necessidade de desenvolvermos um modelo utilizando BERT (atrav\u00e9s de redes neurais), o time optou por desenvolver um modelo baseline, para servir de efeito de compara\u00e7\u00e3o, utilizando o modelo Naive Bayes Multinomial, que \u00e9 um modelo de classifica\u00e7\u00e3o probabil\u00edstico baseado no teorema de Bayes, que assume que a presen\u00e7a de uma caracter\u00edstica em uma classe n\u00e3o est\u00e1 relacionada com a presen\u00e7a de qualquer outra caracter\u00edstica.</p>"},{"location":"Dados/#modelo-naive-bayes-multinomial-baseline","title":"Modelo Naive Bayes Multinomial (Baseline)","text":"<p>O modelo Naive Bayes Multinomial foi escolhido por ser um modelo de classifica\u00e7\u00e3o probabil\u00edstico, que \u00e9 um modelo simples e r\u00e1pido, que pode ser utilizado como baseline para compara\u00e7\u00e3o com outros modelos mais complexos. </p> <p>No Naive Bayes Multinomial, determinamos a probabilidade de uma not\u00edcia pertencer a uma classe, baseado na frequ\u00eancia de palavras que aparecem na not\u00edcia.   Para o treinamento do modelo, foi utilizado o dataset rotulado (701 not\u00edcias).  Sendo separado em 80% para treino (560 not\u00edcias) e 20% (130 not\u00edcias) para valida\u00e7\u00e3o.  </p> <p>Ap\u00f3s o treinamento, foi poss\u00edvel obter o seguinte reporte de classifica\u00e7\u00e3o:</p> Resultado de classifica\u00e7\u00e3o do modelo no conjunto de teste.  (Fonte: Autores, 2023) <p>Enquanto que para o conjunto de valida\u00e7\u00e3o, foi poss\u00edvel obter o seguinte reporte de classifica\u00e7\u00e3o:</p> Resultado de classifica\u00e7\u00e3o do modelo no conjunto de valida\u00e7\u00e3o.  (Fonte: Autores, 2023) <p>Ap\u00f3s o treinamento do modelo, foi poss\u00edvel obter uma acur\u00e1cia de 0.65 no conjunto de teste, e 0.57 no conjunto de valida\u00e7\u00e3o, o que mostra que o modelo possui uma capacidade m\u00e9dia de generaliza\u00e7\u00e3o, e que pode ser utilizado como baseline para compara\u00e7\u00e3o com outros modelos mais complexos.</p>"},{"location":"Dados/#modelo-bert","title":"Modelo BERT","text":"<p>Com a crescente utiliza\u00e7\u00e3o de modelos de Deep Learning para a resolu\u00e7\u00e3o de problemas de NLP, o time optou por utilizar o modelo BERT, que \u00e9 um modelo de Deep Learning desenvolvido pelo Google, que possui uma arquitetura baseada em redes neurais, e que possui um desempenho superior a outros modelos de NLP, como o Naive Bayes Multinomial. </p> <p>O modelo BERT \u00e9 utilizado como um modelo pr\u00e9-treinado, que \u00e9 treinado em um grande volume de dados, e que pode ser utilizado para resolver problemas de NLP, como classifica\u00e7\u00e3o de texto, sumariza\u00e7\u00e3o de texto, entre outros. </p> <p>Para a aplica\u00e7\u00e3o do modelo no projeto, foi necess\u00e1rio realizar o fine-tuning do modelo, que \u00e9 o processo de treinar o modelo pr\u00e9-treinado em um conjunto de dados espec\u00edfico para o problema que se deseja resolver. </p> <p>Para o treinamento do modelo, foi utilizado o dataset rotulado (701 not\u00edcias).  Sendo separado em 80% para treino (562 not\u00edcias) e 20% (112 not\u00edcias) para valida\u00e7\u00e3o.  </p> <p>Ap\u00f3s o treinamento, foi poss\u00edvel obter o seguinte reporte de classifica\u00e7\u00e3o para o conjunto de teste:</p> Resultado de classifica\u00e7\u00e3o do modelo no conjunto de teste.  (Fonte: Autores, 2023) Resultado de classifica\u00e7\u00e3o do modelo no conjunto de valida\u00e7\u00e3o.  (Fonte: Autores, 2023)"},{"location":"Dados/#consideracoes-sobre-o-modelo","title":"Considera\u00e7\u00f5es sobre o modelo","text":"<p>Ap\u00f3s o treinamento dos modelos, foi poss\u00edvel obter os seguintes resultados:</p> Modelo Quantidade de Not\u00edcias Acur\u00e1cia (Teste) Acur\u00e1cia (Valida\u00e7\u00e3o) Precis\u00e3o  (V) Recall  (V) F1-Score(V) Naive Bayes Multinomial 560 0.65 0.57 0.39 0.57 0.46 BERT 701 0.75 0.78 0.78 0.78 0.77 <p>V*: Conjunto de valida\u00e7\u00e3o contendo 30 not\u00edcias. O mesmo \u00e9 executado no Naive e BERT para compara\u00e7\u00e3o. </p> <p>Por se tratar de um modelo de Deep Learning, o BERT possui uma acur\u00e1cia superior ao Naive Bayes Multinomial, que \u00e9 um modelo de Machine Learning tradicional.  Entretanto, o modelo BERT possui uma precis\u00e3o inferior ao Naive Bayes Multinomial, o que pode ser explicado pela quantidade de dados de treinamento. Para uma entrega futura, \u00e9 necess\u00e1rio que o modelo BERT seja treinado com um volume maior de dados, para que seja poss\u00edvel obter uma precis\u00e3o maior, e que possa ser utilizado no Radar da Soja.</p> <p>Contundo, \u00e9 nitido que o modelo BERT possui uma acur\u00e1cia superior ao Naive Bayes Multinomial, o que mostra que o modelo BERT possui uma capacidade de generaliza\u00e7\u00e3o superior ao Naive Bayes Multinomial, e que pode ser utilizado como modelo de classifica\u00e7\u00e3o no Radar da Soja.</p>"},{"location":"Dados/#deploy-do-modelo","title":"Deploy do modelo","text":"<p>Para que o modelo possa ser utilizado no Radar da Soja possa ser integrado na plataforma, foi necess\u00e1rio realizar dois deploys do modelo: Integra\u00e7\u00e3o no Pipeline de ingest\u00e3o de not\u00edcias na plataforma e cria\u00e7\u00e3o de uma API para que seja feito a intera\u00e7\u00e3o do modelo. O usu\u00e1rio digitaria o texto da not\u00edcia e o modelo retornaria a classifica\u00e7\u00e3o da not\u00edcia, com suas respectivas probabilidades.</p>"},{"location":"Dados/#pipeline-de-classificacao","title":"Pipeline de classifica\u00e7\u00e3o","text":"<p>Para o Pipeline de classifica\u00e7\u00e3o, foi incrementar a tarefa j\u00e1 criada para o Airflow, para que ao concluir a ingest\u00e3o de not\u00edcias ao armazenamento, o modelo fosse executado, e que a classifica\u00e7\u00e3o encaminhada a plataforma atrav\u00e9s da aplica\u00e7\u00e3o Backend. Para atingir esse objetivo, foi necess\u00e1rio incluir os arquivos dos modelos (Para o Naive Bayes Multinomial, foi necess\u00e1rio incluir o arquivo <code>naive_bayes.pkl</code>, e para o BERT, foi necess\u00e1rio incluir os arquivos <code>modelo_soja_rede_neural.pt</code>).</p>"},{"location":"Dados/#api-de-classificacao","title":"API de classifica\u00e7\u00e3o","text":"<p>Para que outras aplica\u00e7\u00f5es do Radar da Soja pudesse interagir com o modelo, foi necess\u00e1rio criar uma API para que fosse poss\u00edvel realizar a classifica\u00e7\u00e3o de not\u00edcias. Para isso, foi necess\u00e1rio criar uma API utilizando a ferramenta FastAPI, que \u00e9 uma ferramenta de desenvolvimento de APIs de alto desempenho, que utiliza a sintaxe de Python, e que possui uma documenta\u00e7\u00e3o autom\u00e1tica atrav\u00e9s do Swagger.  Para a cria\u00e7\u00e3o da API, foi necess\u00e1rio criar um endpoint que recebesse o texto da not\u00edcia, e que retornasse a classifica\u00e7\u00e3o da not\u00edcia, com suas respectivas probabilidades, foi necess\u00e1rio carregar o modelo treinado, e que fosse poss\u00edvel realizar a classifica\u00e7\u00e3o da not\u00edcia. </p>"},{"location":"Ferramentas/ferramentas/","title":"Ferramentas","text":""},{"location":"Ferramentas/ferramentas/#ferramentas","title":"Ferramentas","text":"<p>O time Comitiva Esperan\u00e7a est\u00e1 utilizando Docker para a cria\u00e7\u00e3o de containers, e o Docker Compose para a cria\u00e7\u00e3o de containers multiplataforma. A utiliza\u00e7\u00e3o de Dockers permite que o time possa trabalhar em ambientes isolados, e que possam ser facilmente replicados em outros ambientes. A principal possibilidade \u00e9 a facilidade em publicar o projeto em servidores Cloud, como o Azure, AWS, Google Cloud, etc.</p>"},{"location":"Ferramentas/ferramentas/#arquitetura","title":"Arquitetura","text":"<p>A arquitetura do projeto \u00e9 composta por 3 containers, sendo eles:</p> <ul> <li>Data Plataform: Container respons\u00e1vel por manter ferramentas de Data Science, como Jupyter, Airflow, Label Studio, etc.</li> <li>Backend: Container respons\u00e1vel por manter a API do projeto, que ser\u00e1 utilizada para a comunica\u00e7\u00e3o com o Frontend.</li> <li>Frontend: Container respons\u00e1vel por manter a interface do projeto, que ser\u00e1 utilizada para a intera\u00e7\u00e3o com o usu\u00e1rio.</li> </ul> <p></p>"},{"location":"Ferramentas/ferramentas/#apache-airflow","title":"Apache Airflow","text":"<p>O Apache Airflow \u00e9 uma plataforma de orquestra\u00e7\u00e3o de fluxos de trabalho (workflow) de c\u00f3digo aberto que permite aos usu\u00e1rios programar, agendar e monitorar tarefas em fluxos de trabalho complexos.</p>"},{"location":"Ferramentas/ferramentas/#funcionalidades","title":"Funcionalidades","text":"<ul> <li>Programa\u00e7\u00e3o de tarefas em fluxos de trabalho complexos utilizando uma sintaxe simples de Python.</li> <li>Agendamento de tarefas baseado em tempo, eventos ou depend\u00eancias.</li> <li>Monitoramento em tempo real do status das tarefas e fluxos de trabalho.</li> <li>Gerenciamento de depend\u00eancias entre tarefas.</li> <li>Recupera\u00e7\u00e3o autom\u00e1tica de falhas de tarefas.</li> <li>Integra\u00e7\u00e3o com diversos servi\u00e7os de armazenamento e processamento de dados, incluindo Hadoop, Amazon S3 e Google Cloud Storage.</li> </ul>"},{"location":"Ferramentas/ferramentas/#vantagens","title":"Vantagens","text":"<p>Algumas vantagens de utilizar o Apache Airflow s\u00e3o:</p> <p>Flexibilidade: o Airflow permite criar fluxos de trabalho complexos com v\u00e1rias tarefas interdependentes de maneira simples e flex\u00edvel, utilizando a sintaxe de Python.  Escalabilidade: o Airflow pode ser escalado horizontalmente para gerenciar fluxos de trabalho de grande escala, com suporte a m\u00faltiplos executores, incluindo local, Celery e Kubernetes.   Monitoramento em tempo real: o Airflow oferece uma interface de usu\u00e1rio web que permite monitorar em tempo real o status das tarefas e fluxos de trabalho, al\u00e9m de gerar m\u00e9tricas e logs para an\u00e1lise.   Comunidade ativa: o Airflow \u00e9 mantido por uma comunidade de desenvolvedores ativa e tem suporte de grandes empresas, como Airbnb, Google e Lyft, garantindo sua evolu\u00e7\u00e3o e melhoria cont\u00ednuas.  </p>"},{"location":"Ferramentas/ferramentas/#label-studio","title":"Label Studio","text":"<p>Label Studio O Label Studio \u00e9 uma plataforma de marca\u00e7\u00e3o de dados (data labeling) de c\u00f3digo aberto que permite criar tarefas de marca\u00e7\u00e3o de forma simples e escal\u00e1vel. Algumas de suas funcionalidades incluem:</p>"},{"location":"Ferramentas/ferramentas/#funcionalidades_1","title":"Funcionalidades","text":"<ul> <li>Cria\u00e7\u00e3o de projetos de marca\u00e7\u00e3o personalizados com configura\u00e7\u00f5es espec\u00edficas.</li> <li>Possibilidade de criar modelos de anota\u00e7\u00e3o personalizados.</li> <li>Integra\u00e7\u00e3o com ferramentas de treinamento de modelos de machine learning.</li> <li>Possibilidade de exportar os dados marcados em diversos formatos, incluindo JSON, CSV e TensorFlow Record.</li> <li>Suporte a m\u00faltiplas interfaces de usu\u00e1rio, incluindo web, desktop e m\u00f3vel.</li> </ul>"},{"location":"Ferramentas/ferramentas/#vantagens_1","title":"Vantagens","text":"<p>Algumas vantagens de utilizar o Label Studio s\u00e3o:</p> <p>Flexibilidade: o Label Studio permite criar projetos de marca\u00e7\u00e3o personalizados com configura\u00e7\u00f5es espec\u00edficas e modelos de anota\u00e7\u00e3o personalizados, adaptados \u00e0s necessidades espec\u00edficas do usu\u00e1rio.  Escalabilidade: o Label Studio pode ser utilizado em conjunto com ferramentas de treinamento de modelos de machine learning para lidar com grandes volumes de dados de forma escal\u00e1vel.  Integra\u00e7\u00e3o: o Label Studio \u00e9 compat\u00edvel com diversas ferramentas de machine learning e permite integrar a marca\u00e7\u00e3o de dados diretamente ao processo de treinamento de modelos.  Exporta\u00e7\u00e3o: o Label Studio permite exportar os dados marcados em diversos formatos, tornando f\u00e1cil o compartilhamento e a utiliza\u00e7\u00e3o desses dados em outros projetos.  Interface de usu\u00e1rio: o Label Studio oferece diversas interfaces de usu\u00e1rio para facilitar a marca\u00e7\u00e3o de dados em diferentes plataformas. </p>"},{"location":"Ferramentas/ferramentas/#fast-api","title":"Fast API","text":"<p>O FastAPI \u00e9 um framework de desenvolvimento web de alto desempenho, de c\u00f3digo aberto, baseado em Python 3.6+ que utiliza o padr\u00e3o OpenAPI para construir APIs RESTful. Algumas das suas principais funcionalidades incluem:</p>"},{"location":"Ferramentas/ferramentas/#funcionalidades_2","title":"Funcionalidades","text":"<p>Roteamento de requisi\u00e7\u00f5es HTTP utilizando o padr\u00e3o RESTful. Suporte a especifica\u00e7\u00f5es OpenAPI e Swagger para documenta\u00e7\u00e3o de APIs. Valida\u00e7\u00e3o de tipos de dados utilizando o Pydantic, incluindo convers\u00e3o autom\u00e1tica de tipos de dados, como JSON para objetos Python. Suporte a CORS (Cross-Origin Resource Sharing) para controle de acesso a recursos em outras origens. Integra\u00e7\u00e3o com diversos servi\u00e7os de autentica\u00e7\u00e3o, como OAuth2 e JWT (JSON Web Tokens). Suporte a ASGI (Asynchronous Server Gateway Interface) para cria\u00e7\u00e3o de aplica\u00e7\u00f5es ass\u00edncronas de alto desempenho.</p>"},{"location":"Ferramentas/ferramentas/#vantagens_2","title":"Vantagens","text":"<p>Algumas vantagens de utilizar o FastAPI s\u00e3o:</p> <p>Alto desempenho: o FastAPI \u00e9 um dos frameworks mais r\u00e1pidos dispon\u00edveis para Python, oferecendo alto desempenho em aplica\u00e7\u00f5es ass\u00edncronas.  Tipagem de dados: o FastAPI utiliza o Pydantic para validar tipos de dados automaticamente, tornando mais f\u00e1cil o desenvolvimento de APIs seguras e confi\u00e1veis.  Documenta\u00e7\u00e3o autom\u00e1tica: o FastAPI utiliza especifica\u00e7\u00f5es OpenAPI e Swagger para gerar documenta\u00e7\u00e3o autom\u00e1tica das APIs, facilitando o desenvolvimento e a manuten\u00e7\u00e3o de aplica\u00e7\u00f5es.  Autentica\u00e7\u00e3o: o FastAPI oferece suporte a diversos servi\u00e7os de autentica\u00e7\u00e3o, tornando mais f\u00e1cil a implementa\u00e7\u00e3o de pol\u00edticas de seguran\u00e7a em aplica\u00e7\u00f5es.  Comunidade ativa: o FastAPI \u00e9 mantido por uma comunidade de desenvolvedores ativa e tem suporte de grandes empresas, garantindo sua evolu\u00e7\u00e3o e melhoria cont\u00ednuas. </p>"},{"location":"Frontend/","title":"Frontend","text":""},{"location":"Frontend/#radar-da-soja-web","title":"Radar da soja Web","text":""},{"location":"Frontend/#como-executar","title":"\ud83c\udd98 Como executar?","text":"<p>A plataforma \u00e9 feita em Next e usando Typescript: - Nextjs - Typescript</p> <p>Para executar a plataforma, \u00e9 necess\u00e1rio ter o Docker instalado na m\u00e1quina. </p> <p>Inicialmente, clone o reposit\u00f3rio para sua m\u00e1quina, seguindo os passos abaixos: <pre><code>git clone\n</code></pre> Em seguida, execute o comando: <pre><code>npm install\n</code></pre> Em seguida, execute o comando: <pre><code>docker-compose up -d --build\n</code></pre></p> <p>Ap\u00f3s a execu\u00e7\u00e3o do comando, a plataforma estar\u00e1 dispon\u00edvel para uso.  - Para acessar, acesse o endere\u00e7o: http://localhost:3000</p>"},{"location":"Frontend/#mais-informacoes","title":"Mais informa\u00e7\u00f5es","text":"<p>Para saber mais sobre o NextJS e suas tecnologias, acesse os seguintes recursos:</p> <ul> <li>Next.js Documentation </li> <li>Learn Next.js </li> </ul>"},{"location":"Frontend/#nextjs-rendering","title":"Next.JS Rendering","text":""},{"location":"Frontend/#pre-rendering","title":"Pre-rendering","text":"<p>Por padr\u00e3o, o Next.js pr\u00e9-renderiza cada p\u00e1gina. Isso significa que o Next.js gera o HTML para cada p\u00e1gina com anteced\u00eancia, em vez de ter tudo feito pelo JavaScript do lado do cliente. O pr\u00e9-processamento pode resultar em melhor desempenho e SEO</p>"},{"location":"Frontend/#ssr-server-side-rendering","title":"SSR: Server-side rendering","text":"<p>O Next.js ir\u00e1 pr\u00e9-renderizar esta p\u00e1gina em cada solicita\u00e7\u00e3o usando os dados retornados por getServerSideProps.</p> <ul> <li>Server-side Doc</li> </ul>"},{"location":"Frontend/#ssg-static-site-generation","title":"SSG: Static-site generation","text":"<p>O Next.js ir\u00e1 pr\u00e9-renderizar esta p\u00e1gina no momento da constru\u00e7\u00e3o usando as props retornadas por getStaticProps.</p> <p>No desenvolvimento (next dev), getStaticProps ser\u00e1 chamado em cada solicita\u00e7\u00e3o.</p> <ul> <li>Static-site Doc</li> </ul>"},{"location":"Frontend/#csr-client-side-rendering","title":"CSR: Client-side rendering","text":"<p>Se feito no n\u00edvel da p\u00e1gina, os dados s\u00e3o buscados em tempo de execu\u00e7\u00e3o, e o conte\u00fado da p\u00e1gina \u00e9 atualizado conforme os dados mudam. Quando usado no n\u00edvel do componente, os dados s\u00e3o buscados no momento da montagem do componente, e o conte\u00fado do componente \u00e9 atualizado conforme os dados mudam.</p> <ul> <li>Client-side Doc</li> </ul>"},{"location":"Frontend/#pacotes-instalados","title":"Pacotes Instalados","text":"<ol> <li>Axios</li> <li>Tailwind</li> <li>ChartJS</li> <li>FlowBite</li> <li>Eslint</li> <li>https://github.com/jsx-eslint/eslint-plugin-react</li> </ol>"},{"location":"Home/","title":"Comitiva Esperan\u00e7a \ud83c\udf1f","text":"<p>Organiza\u00e7\u00e3o destinada ao time Comitiva Esperan\u00e7a do programa &lt;/pantanal.dev&gt; \ud83d\ude80, um programa de capacita\u00e7\u00e3o imersiva em tecnologias inovadoras que tem como objetivo capacitar e apresentar oportunidades de trabalho remoto no mercado financeiro nacional \ud83d\udcbc. </p> <p></p>"},{"location":"Home/#sobre-o-desafio-pantanaldev","title":"Sobre o desafio &lt;/pantanal.dev&gt;","text":"<p>Entre os dias 01/04/2023 e 20/05/2023, foi realizado o m\u00f3dulo Arara Azul, focado em Machine Learning, do programa &lt;/pantanal.dev&gt;, um programa desenvolvido por professores da Faculdade de Computa\u00e7\u00e3o da UFMS em parceira com as empresas B3 a bolsa do Brasil, BLK, PDtec e Neoway.  Durante esse per\u00edodo foi proposto a n\u00f3s do time Comitiva Esperan\u00e7a e a outras 9 equipes, o desafio de \"Treinar um algoritmo de Machine Learning capaz de classificar o sentimento de textos de not\u00edcias de Jornais ou Redes Sociais em (Positivo, Neutro ou Negativo)\".   Cabia a cada time definir e construir um produto queresolva um problema real e entregue valor aos seus usu\u00e1rios com esse modelo proposto. </p>"},{"location":"Home/#participantes","title":"Participantes \ud83d\ude4b\u200d\u2640\ufe0f\ud83d\ude4b\u200d\u2642\ufe0f","text":"<p>O time Comitiva Esperan\u00e7a \u00e9 composto por 4 pessoas, de \u00e1reas multidisciplinares. Todos atuam como Data Scientist por\u00e9m exercem o papel prim\u00e1rio descrito abaixo:</p> Vitor Lameir\u00e3o          Engenharia de Software  Product Owner Maycon Felipe Mota          Engenharia de Software  Data Engineer Eduardo Godoy          Engenharia de Software  Backend Engineer Arthur Ramires          Sistema de Informa\u00e7\u00e3o Frontend Engineer Andrezza Andrade          Neoway \ud83d\udc51 Mentora"},{"location":"Home/#tabela-de-versionamento","title":"Tabela de Versionamento","text":"Data Vers\u00e3o Descri\u00e7\u00e3o Autor(es) 03/05/2023 1.0 Cria\u00e7\u00e3o do documento Vitor Lameir\u00e3o"},{"location":"Infraestrutura/atualmente/","title":"Atualmente","text":"<p>Atualmente n\u00f3s estamos utilizando a Microsoft Azure como provedor de nuvem. Na Azure, estamos utilizando o servi\u00e7o Azure Kubernetes Services (AKS), que \u00e9 um servi\u00e7o que permite a implementa\u00e7\u00e3o e dimensionamento de containeres em um cluster de Kubernetes gerenciado.</p>"},{"location":"Infraestrutura/atualmente/#acessos","title":"Acessos","text":"<ul> <li>Para acessar a aplica\u00e7\u00e3o Frontend, utilize o endere\u00e7o: http://20.190.253.88/</li> <li>Para acessar a aplica\u00e7\u00e3o Backend, utilize o endere\u00e7o: http://20.190.249.236/swagger/index.html</li> <li>Para acessar a aplica\u00e7\u00e3o Predict, utilize o endere\u00e7o: http://20.96.249.168/docs</li> <li>Para acessar a aplica\u00e7\u00e3o Label Studio, utilize o endere\u00e7o: http://20.96.249.166/user/login/</li> </ul>"},{"location":"Infraestrutura/como_executar/","title":"Como executar local","text":"<p>Para executar a plataforma, \u00e9 necess\u00e1rio ter o Docker instalado na m\u00e1quina. .  Tamb\u00e9m \u00e9 necess\u00e1rio ter uma chave SSH configurada no Github. Para isso, siga os passos abaixo:</p> <ul> <li>Gerando uma chave SSH</li> </ul>"},{"location":"Infraestrutura/como_executar/#frontend","title":"Frontend","text":"<p>Inicialmente, clone o reposit\u00f3rio para sua m\u00e1quina, seguindo os passos abaixos: <pre><code>git clone git@github.com:comitivaesperanca/frontend.git\n</code></pre> Em seguida, execute o comando: <pre><code>docker-compose up -d --build\n</code></pre></p>"},{"location":"Infraestrutura/como_executar/#backend","title":"Backend","text":"<p>Inicialmente, clone o reposit\u00f3rio para sua m\u00e1quina, seguindo os passos abaixos: <pre><code>git clone git@github.com:comitivaesperanca/backend.git\n</code></pre> Em seguida, execute o comando: <pre><code>docker-compose up -d --build\n</code></pre></p>"},{"location":"Infraestrutura/como_executar/#dados","title":"Dados","text":"<p>Inicialmente, clone o reposit\u00f3rio para sua m\u00e1quina, seguindo os passos abaixos: <pre><code>git clone git@github.com:comitivaesperanca/data.git\n</code></pre> Em seguida, execute o comando: <pre><code>docker-compose up -d --build\n</code></pre> Acessos aos sistemas da plataforma:</p> <ul> <li>Airflow: http://localhost:8080</li> <li>LabelStudio: http://localhost:8005</li> <li>Jupyter: http://localhost:8888</li> <li>API Predict: http://localhost:7000</li> </ul>"},{"location":"Infraestrutura/sobre/","title":"Sobre","text":""},{"location":"Infraestrutura/sobre/#introducao","title":"Introdu\u00e7\u00e3o","text":"<p>A infraestrutura do Radar da Soja \u00e9 composta por 3 servi\u00e7os principais: o banco de dados, backend, frontend e microservi\u00e7o de predict. Todos esses servi\u00e7os s\u00e3o executados em Kubernetes, que \u00e9 uma plataforma de orquestra\u00e7\u00e3o de cont\u00eaineres de c\u00f3digo aberto que automatiza a implanta\u00e7\u00e3o, o dimensionamento e o gerenciamento de aplicativos em cont\u00eaineres. O Kubernetes foi escolhido por ser uma ferramenta que permite a execu\u00e7\u00e3o de aplica\u00e7\u00f5es em cont\u00eaineres de forma escal\u00e1vel e confi\u00e1vel, al\u00e9m de ser uma ferramenta amplamente utilizada no mercado, permitindo realizar a implanta\u00e7\u00e3o do Radar da Soja em diversos provedores de nuvem como AWS, Azure e Google Cloud.</p>"},{"location":"Infraestrutura/sobre/#docker","title":"Docker","text":"<p>Todos os servi\u00e7os do Radar da Soja s\u00e3o executados em cont\u00eaineres Docker. O Docker \u00e9 uma plataforma de c\u00f3digo aberto que permite que voc\u00ea crie, teste e implante aplicativos rapidamente. O Docker permite empacotar um aplicativo com todas as partes de que ele precisa, como bibliotecas e outras depend\u00eancias, e envi\u00e1-lo como um \u00fanico pacote. Ao fazer isso, gra\u00e7as ao cont\u00eainer, o aplicativo ser\u00e1 executado em qualquer ambiente: de uma m\u00e1quina f\u00edsica a uma m\u00e1quina virtual, em um data center ou na nuvem. Para executar o Radar da Soja em um ambiente local, \u00e9 necess\u00e1rio instalar o Docker e o Docker Compose. </p> <ul> <li>Docker</li> <li>Docker Compose</li> </ul>"},{"location":"Infraestrutura/sobre/#kubernetes","title":"Kubernetes","text":"<p>O Kubernetes \u00e9 uma plataforma de orquestra\u00e7\u00e3o de cont\u00eaineres de c\u00f3digo aberto que automatiza a implanta\u00e7\u00e3o, o dimensionamento e o gerenciamento de aplicativos em cont\u00eaineres. O Kubernetes foi escolhido por ser uma ferramenta que permite a execu\u00e7\u00e3o de aplica\u00e7\u00f5es em cont\u00eaineres de forma escal\u00e1vel e confi\u00e1vel, al\u00e9m de ser uma ferramenta amplamente utilizada no mercado, permitindo realizar a implanta\u00e7\u00e3o do Radar da Soja em diversos provedores de nuvem como AWS, Azure e Google Cloud.</p> <p>Para executar em Kubernetes, foi necess\u00e1rio criar quatro deployments (Frontend, Backend, Predict e Label Studio) criando pods e respectivos services contendo Load Balancers para cada um dos servi\u00e7os. </p>"},{"location":"Infraestrutura/sobre/#deployments","title":"Deployments","text":"<p>O Deployments \u00e9 um objeto do Kubernetes que permite a cria\u00e7\u00e3o de pods e replica\u00e7\u00f5es dos mesmos. Para cada servi\u00e7o do Radar da Soja, foi criado um deployment, que \u00e9 respons\u00e1vel por criar e gerenciar os pods e replica\u00e7\u00f5es dos mesmos.</p> Objetos criado no servi\u00e7o de Kubernetes da Azure (Fonte: Autores, 2023)"},{"location":"Infraestrutura/sobre/#pods","title":"Pods","text":"<p>O Pod \u00e9 a menor unidade que pode ser criada e gerenciada no Kubernetes. Um pod \u00e9 um grupo de um ou mais cont\u00eaineres, com armazenamento compartilhado (volumes), endere\u00e7o IP e op\u00e7\u00f5es de como executar os cont\u00eaineres. Ele seria o equivalente a uma m\u00e1quina virtual, por\u00e9m com um tamanho muito menor. Para cada servi\u00e7o do Radar da Soja, foi criado um pod, que \u00e9 respons\u00e1vel por executar o servi\u00e7o.</p> Objetos criado no servi\u00e7o de Kubernetes da Azure (Fonte: Autores, 2023)"},{"location":"Infraestrutura/sobre/#services","title":"Services","text":"<p>O Service \u00e9 um objeto do Kubernetes que permite a comunica\u00e7\u00e3o entre os pods. Para cada servi\u00e7o do Radar da Soja, foi criado um service, que \u00e9 respons\u00e1vel por permitir a comunica\u00e7\u00e3o externa com o pod. No servi\u00e7o de Kubernetes da Azure, foi criado um Load Balancer para cada service, que \u00e9 respons\u00e1vel por distribuir as requisi\u00e7\u00f5es entre os pods.</p> Objetos criado no servi\u00e7o de Kubernetes da Azure (Fonte: Autores, 2023)"},{"location":"Infraestrutura/sobre/#postgresql","title":"PostgreSQL","text":"<p>O PostgreSQL \u00e9 um sistema de gerenciamento de banco de dados objeto-relacional (ORDBMS). O PostgreSQL foi escolhido por ser um banco de dados relacional de c\u00f3digo aberto, que possui uma grande comunidade e \u00e9 amplamente utilizado no mercado. Al\u00e9m disso, o PostgreSQL \u00e9 compat\u00edvel com o ORM utilizado no Radar da Soja, o Entity Framework Core. No Radar da Soja, o PostgreSQL \u00e9 utilizado para armazenar os dados das not\u00edcias e dos usu\u00e1rios.</p>"},{"location":"Infraestrutura/sobre/#custos-com-nuvem","title":"Custos com nuvem","text":"<p>Durante a execu\u00e7\u00e3o do projeto, apenas o Apache Airflow n\u00e3o teve seu deploy no cluster de Kubernetes. O custo m\u00e9dio por dia ficou em torno de R$ 5.20 reais, sendo que o maior custo foi com o uso de m\u00e1quinas virtuais, que ficou em torno de R$59.08 reais. O custo total do projeto foi de R$ 115.11. Estimasse que o custo total do projeto seja de R$ 464.82 ao final do m\u00eas. O custo total do projeto pode ser visto na imagem abaixo:</p> Proje\u00e7\u00e3o de custos (Fonte: Autores, 2023) Custo com nuvem durante o desenvolvimento. (Fonte: Autores, 2023)"},{"location":"Organizacao/metodologias/","title":"Metodologias","text":"<p>Nesta p\u00e1gina est\u00e1 descrita todas as metodologias utilizadas para o gerenciamento do projeto Radar da Soja, considerando isso, foram utilizadas algumas pr\u00e1ticas de desenvolvimento das seguintes metodologias \u00e1geis de desenvolvimento de software: Scrum, Kanban e XP   . </p>"},{"location":"Organizacao/metodologias/#scrum","title":"Scrum","text":"<p>Scrum \u00e9 uma metodologia de desenvolvimento \u00e1gil de software que busca entregar valor ao cliente de forma iterativa e incremental. As principais caracter\u00edsticas do Scrum incluem a organiza\u00e7\u00e3o em equiepes multidisciplinares e auto-gerenci\u00e1veis, a utiliza\u00e7\u00e3o de reuni\u00f5es di\u00e1rias para alinhamento das atividades da equipe, uso de um backlog do produto priozado e realiza\u00e7\u00e3o de reuni\u00f5es frequentes para avaliar o que foi progredido durante certo per\u00edodo de tempo. O principal objetivo do Scrum \u00e9 permitir que a equipe entregue um produto de alta qualidade e que atenda \u00e0s necessidades do cliente. </p> <p>Durante o projeto Radar da Soja, o time Comitiva Esperan\u00e7a utilizou as seguintes pr\u00e1ticas da metodologia Scrum: Product Backlog e Daily Meeting</p>"},{"location":"Organizacao/metodologias/#product-backlog","title":"Product Backlog","text":"<p>Na metodologia Scrum, o Product Backlog \u00e9 uma lista ordenada de todas as funcionalidades, requisitos, melhorias e corre\u00e7\u00f5es que comp\u00f5em um determinado produto. Essa lista \u00e9 organizada de acordo com a prioridade definida pelo Product Owner em conjunto com a equipe de desenvolvimento. </p> <p>No projeto Radar da Soja, o Product Backlog pode ser visualizado atr\u00e1ves desse link, no qual foram descritas Hist\u00f3rias de Usu\u00e1rios e Crit\u00e9rios de aceita\u00e7\u00e3o para cada Issue que comp\u00f5em o backlog.</p>"},{"location":"Organizacao/metodologias/#daily-meeting","title":"Daily Meeting","text":"<p>A Daily Meeting \u00e9 uma reuni\u00e3o di\u00e1ria de acompanhamento entre a equipe de desenvolvimento, na qual tem o objetivo de relatar o status do que est\u00e1 sendo desenvolvimento naquele dia e impedimentos que podem acarretar no atraso no desenvolvimento do projeto. </p> <p>No time Comitiva Esperan\u00e7a, a Daily Meeting foi substitu\u00edda por um status report enviado diariamente no grupo do WhatsApp da organiza\u00e7\u00e3o.</p>"},{"location":"Organizacao/metodologias/#kanban","title":"Kanban","text":"<p>O m\u00e9todo Kanban \u00e9 uma abordagem \u00e1gil de gest\u00e3o de processos de software que se concentra na visualiza\u00e7\u00e3o do fluxo de trabalho e na melhoria cont\u00ednua. O objetivo desse m\u00e9todo \u00e9 aumentar a efici\u00eancia do processo, reduzir o tempo de entrega e melhorar a qualidade do produto final por meio da gest\u00e3o visual e na melhoria cont\u00ednua. </p> <p>Durante o projeto Radar da Soja, o time Comitiva Esperan\u00e7a utilizou as seguintes pr\u00e1ticas do m\u00e9todo Kanban: Visualiza\u00e7\u00e3o do fluxo de trabalho e Gest\u00e3o visual.</p>"},{"location":"Organizacao/metodologias/#visualizacao-do-fluxo-de-trabalho","title":"Visualiza\u00e7\u00e3o do fluxo de trabalho","text":"<p>No m\u00e9todo Kanban, a visualiza\u00e7\u00e3o do fluxo de trabalho \u00e9 feita principalmente pelo Quadro Kanban. Ele \u00e9 divido em colunas que representam as etapas do processo, como \"To do\", \"In Progress\" e \"Done\" e, cada item de trabalho \u00e9 representado por um cart\u00e3o ou post-it que \u00e9 movido \u00e0 medida que se progride no processo. </p> <p>Durante o projeto Radar da Soja, foi utilizado utilizado o quadro Kanban como pode-se visualizar atr\u00e1ves desse link. Al\u00e9m das colunas padr\u00f5es, foram adicionados as colunas \"New\", \"Backlog\" e \"In Review\", para que a visualiza\u00e7\u00e3o do trabalho ficasse adequada ao processo de desenvolvimento implementado pelo time. </p>"},{"location":"Organizacao/metodologias/#gestao-visual","title":"Gest\u00e3o visual","text":"<p>No m\u00e9todo Kanban, a gest\u00e3o visual \u00e9 feita atrav\u00e9s de cores diferentes ou \u00edcones que s\u00e3o utilizados para indicar diferentes tipos de trabalho, prioridade ou tamanho dos itens de trabalho. Essa gest\u00e3o visual ajuda a equipe a destacar os itens de trabalho mais urgentes ou cr\u00edticos e assim ajudar a equipe a prioriz\u00e1-los. </p> <p>Durante o projeto Radar da Soja, a gest\u00e3o visual foi feita atrav\u00e9s dos atributos (Size e Priority) de uma Issue no Github Project, como pode ser visto nesse link. Foram utilizados cores e tags para destacar o tamanho e a prioridade do item de trabalho.</p>"},{"location":"Organizacao/metodologias/#extreme-programming-xp","title":"Extreme Programming (XP)","text":"<p>O m\u00e9todo Extreme Programming (XP) \u00e9 uma abordagem \u00e1gil para o desenvolvimento de software que visa maximizar a qualidade e a efici\u00eancia do processo de desenvolvimento. o XP \u00e9 baseado em valores fundamenteis que incluem a comunica\u00e7\u00e3o, simplicaidade, feedback, coragem e respeito. Esses valores orientam todo o processo de desenvolvimento e ajudam a manter o foco nas necessidades do produto. </p> <p>Durante o projeto \"Radar da soja\", o time Comitiva Esperan\u00e7a utilizou as seguintes pr\u00e1ticas do m\u00e9todo XP: Programa\u00e7\u00e3o em Par, Integra\u00e7\u00e3o cont\u00ednua, C\u00f3digo coletivo, Reuno\u00e3o di\u00e1ria e Ritmo sustent\u00e1vel.   </p>"},{"location":"Organizacao/metodologias/#programacao-em-par","title":"Programa\u00e7\u00e3o em Par","text":"<p>No m\u00e9todo XP, a programa\u00e7\u00e3o em par \u00e9 feita por dois programadores que trabalham juntos em um mesmo computador para escrever e revisar o c\u00f3digo, aumentando a quailidade e diminuiando a quantidade de erros.</p> <p>No time Comitiva Esperan\u00e7a, a programa\u00e7\u00e3o em par foi feita principalmente para o desenvolvimento do modelo de intelig\u00eancia artificial, como o objetivo de todos da equipe era aprender sobre Machine Learning, a programa\u00e7\u00e3o em par foi realizada por 4 desenvolvedores atr\u00e1ves do Discord.</p>"},{"location":"Organizacao/metodologias/#integracao-continua","title":"Integra\u00e7\u00e3o cont\u00ednua","text":"<p>No m\u00e9todo XP, a integra\u00e7\u00e3o cont\u00ednua \u00e9 uma pr\u00e1tica que garante que todas as mudan\u00e7as no c\u00f3digo sejam integradas com frequ\u00eancia ao reposit\u00f3rio principal, evitando assim conflitos e problemas decorrentes da integra\u00e7\u00e3o tardia de c\u00f3digos independentes. </p> <p>No projeto \"Radar da soja\", todas as altera\u00e7\u00f5es e incrementos nos c\u00f3digos eram associados frequentemente nos reposit\u00f3rios centrais data, frontend, backend e docs, como pode ser visto atrav\u00e9s dos n\u00fameros de commits e pull-requests dos reposit\u00f3rios atrav\u00e9s desse link.</p>"},{"location":"Organizacao/metodologias/#codigo-coletivo","title":"C\u00f3digo coletivo","text":"<p>No m\u00e9todo XP, o c\u00f3digo coletivo \u00e9 uma pr\u00e1tica de propriepidade coletiva do c\u00f3digo, ou seja, cada membro da equipe pode trabalhar em qualquer parte do sistema a qualquer momento. Essa pr\u00e1tica permite que o sistema evolua mantendo o c\u00f3digo mais simples poss\u00edvel e garante que todos os membros do time possuam conhecimento do sistema em sua totalidade. </p> <p>No projeto \"Radar da soja\", qualquer pessoa do time Comitiva Esperan\u00e7a pode fazer altera\u00e7\u00f5es em qualquer um dos reposit\u00f3rios sem necessidade de autoriza\u00e7\u00e3o de outro pessoa. At\u00e9 por isso, para aprova\u00e7\u00e3o de um Pull Request n\u00e3o \u00e9 necess\u00e1rio a revis\u00e3o de nenhum outro membro da equipe.</p>"},{"location":"Organizacao/metodologias/#reuniao-diaria","title":"Reuni\u00e3o di\u00e1ria","text":"<p>A reuni\u00e3o di\u00e1ria do XP e do Scrum possui, no geral, o mesmo prop\u00f3sito, um status report das atividades que foram realizadas ontem e das atividades que est\u00e3o sendo desenvolvidas, assim todos os membros do time possuem conhecimento sobre o andamento geral do projeto. </p> <p>No time Comitiva Esperan\u00e7a, como dito na Daily Meeting do Scrum, as reuni\u00f5es di\u00e1rias foram substituidas por um status report di\u00e1rio, enviado no grupo do WhatsApp da organiza\u00e7\u00e3o, das atividades dos membros da equipe.</p>"},{"location":"Organizacao/metodologias/#ritmo-sustentavel","title":"Ritmo sustent\u00e1vel","text":"<p>No m\u00e9todo XP, o ritmo sustent\u00e1vel \u00e9 uma pr\u00e1tica que consiste em trabalhar respeitando os limiticos f\u00edsicos e demonstrando respeito pela individualidade de cada membro da equipe. Dessa forma, todos os membros da equipe garante a sa\u00fade do ponto de vista f\u00edsico e mental. </p> <p>Considerando que todos os membros do time Comitiva Esperan\u00e7a possuem empregos fixos e de tempo integral, a pr\u00e1tica do ritmo sustent\u00e1vel foi de extrema necessidade para garantia do sucesso do projeto, por isso, cada membro tinha liberdade de executar as atividades previstas a qualquer momento desejado e da forma que achasse adequada.</p>"},{"location":"Organizacao/metodologias/#tabela-de-versionamento","title":"Tabela de Versionamento","text":"Data Vers\u00e3o Descri\u00e7\u00e3o Autor(es) 03/05/2023 1.0 Cria\u00e7\u00e3o do documento Vitor Lameir\u00e3o"},{"location":"Produto/analisando_mercado/","title":"An\u00e1lise do Mercado","text":""},{"location":"Produto/analisando_mercado/#entendendo-o-mercado","title":"Entendendo o mercado","text":"<p>A partir de uma an\u00e1lise abrangente do mercado da soja, surgiram muitos insights sobre como poder\u00edamos criar um produto que resolvesse os problemas mencionados no contexto geral. Considerando esses estudos de mercado, muitas perguntas e afirma\u00e7\u00f5es surgiram para n\u00f3s da equipe e, afim de organizar nossas ideias, elaboramos uma matriz CSD que clusteriza as \"Certezas\", \"Suposi\u00e7\u00f5es\" e \"D\u00favidas\" de um determinado assunto. </p> <p>Essa Matriz CSD n\u00e3o s\u00f3 nos ajudou a esclarecer nossas ideias, mas tamb\u00e9m serviu como base para as pesquisas de mercado que conduzimos e para toda a descoberta do Radar da Soja.</p> <p></p> <p> Acima est\u00e1 ilustrado nossa Matriz CSD criada na ferramenta MIRO. </p>"},{"location":"Produto/analisando_mercado/#pesquisa-de-mercado","title":"Pesquisa de mercado","text":"<p>O objetivo dessa pesquisa foi responder as suposi\u00e7\u00f5es e d\u00favidas da equipe Comitiva Esperan\u00e7a, principalmente sobre as pessoas que atuam com o mercado da soja e seus problemas enfretados.</p> <p>Para realizar a pesquisa, foi criado um formul\u00e1rio no Google contendo diversas perguntas sobre quest\u00f5es relacionadas aos problemas encontrados mercado da soja, as pessoas que atuam com essa commodity e sobre as not\u00edcias desse mercado. O formul\u00e1rio foi divulgado inicialmente em grupos do Facebook e WhatsApp e, posteriormente, individualmente para cada pessoa nessas redes.</p>"},{"location":"Produto/analisando_mercado/#estrategia-para-divulgacao","title":"Estrat\u00e9gia para divulga\u00e7\u00e3o","text":"<p>Durante o tempo vigente da pesquisa, foram utilizados duas estrat\u00e9gias distintas para divulga\u00e7\u00e3o da pesquisa.</p> <p>A primeira estrat\u00e9gia utilizada foi divulgar a pesquisa em grupos relacionados ao agroneg\u00f3cio. No entanto, essa abordagem n\u00e3o se mostrou eficaz devido \u00e0 falta de personaliza\u00e7\u00e3o e intera\u00e7\u00e3o humana. N\u00f3s apenas compartilhamos o formul\u00e1rio nessas comunidades e esperamos pelas respostas, o que resultou em apenas uma \u00fanica resposta obtida por meio desse m\u00e9todo.</p> <p>A segunda estrat\u00e9gia adotada consistiu em divulgar o formul\u00e1rio de maneira personalizada e humanizada, conversando individualmente com cada pessoa. Essa abordagem nos trouxe resultados significativos, pois as pessoas se sentiram envolvidas em algo maior, que era ajudar universit\u00e1rios a construir um produto valioso para eles. Como resultado dessa estrat\u00e9gia, conseguimos obter 9 respostas para nossa pesquisa.</p>"},{"location":"Produto/analisando_mercado/#numeros-atingidos","title":"N\u00fameros atingidos","text":"<p>Uma das maiores dificuldades para a realiza\u00e7\u00e3o dessa pesquisa foi o contato com pessoas do mercado, isso reflete diretamente na taxa de resposta da pesquisa: foram enviadas 231 mensagens individualizadas para participantes de grupos de agroneg\u00f3cio e obtivemos 10 respostas em nosso formul\u00e1rio.</p> <p>Isso demonstrou uma caracter\u00edstica para esse grupo de pessoas, a falta de tempo. Normalmente ficam o dia inteiro atarefados com suas atividades de trabalho e n\u00e3o conseguem encontrar momentos para responder formul\u00e1rios em seu WhatsApp.</p>"},{"location":"Produto/analisando_mercado/#pesquisa-para-entendimento-do-mercado","title":"Pesquisa para entendimento do mercado","text":"<p>Abaixo segue os dados obtidos para cada uma das perguntas realizadas.</p> <p> Pergunta realizada com o intuito de compreender a idade m\u00e9dia das pessoas envolvidas com o mercado da soja </p> <p> Pergunta realizada com o intuito de compreender quais eram os cargos/responsabilidades dos participantes </p> <p> Pergunta realizada com o intuito de descobrir quais os principais meios de negocia\u00e7\u00e3o da soja </p> <p> Pergunta realizada com o intuito de entender quais os principais problemas que afetam as opera\u00e7\u00f5es de compra e venda da soja </p> <p> Pergunta criada para obter dados de visualiza\u00e7\u00e3o de not\u00edcias sobre o mercado da soja </p> <p> Pergunta criada para entender se os participantes baseiam suas opera\u00e7\u00f5es de compra e venda em not\u00edcias do mercado </p> <p> Pergunta criada para obter dados dos sites com not\u00edcias da soja mais visitados </p> <p> Pergunta criada para entender se os partipantes consideram a ideia do Radar da Soja \u00fatil e valiosa </p>"},{"location":"Produto/analisando_mercado/#resultado-obtidos","title":"Resultado obtidos","text":"<p>A pesquisa realizada com profissionais do mercado da soja trouxe importantes insights sobre as principais necessidades e problemas enfrentados por essas pessoas. </p> <p>Com base na pesquisa e ap\u00f3s an\u00e1lise minuciosa dos dados coletados, n\u00f3s da Comitiva Esperan\u00e7a tivemos a oportunidade de identificar os nossos potenciais usu\u00e1rios e clientes. </p> <p>Essas informa\u00e7\u00f5es foram fundamentais para que pud\u00e9ssemos criar um produto sob medida que atenda \u00e0s necessidades desses consumidores e resolva os problemas encontrados.</p>"},{"location":"Produto/analisando_mercado/#tabela-de-versionamento","title":"Tabela de Versionamento","text":"Data Vers\u00e3o Descri\u00e7\u00e3o Autor(es) 10/05/2023 1.0 Cria\u00e7\u00e3o do documento Vitor Lameir\u00e3o"},{"location":"Produto/brainstorming/","title":"Brainstorming de Funcionalidades","text":"<p>Ap\u00f3s criarmos nossa Vis\u00e3o do Produto, que gerou um entendimento comum sobre o produto que ser\u00e1 desenvolvido por toda a equipe Comitiva Esperan\u00e7a, seguimos para a segunda etapa da descoberta do Radar da Soja, o Brainstorming de Funcionalidades.</p>"},{"location":"Produto/brainstorming/#aplicacao-do-metodo","title":"Aplica\u00e7\u00e3o do m\u00e9todo","text":"<p>Para aplicar o Brainstorming de Funcionalidades, criamos um quadro na ferramenta Miro, onde cada membro da equipe poderia imaginar e escrever uma funcionalidade que julgava ser valiosa para o produto. Nesta etapa, n\u00e3o validamos nenhuma das funcionalidades inseridas, pois o objetivo \u00e9 coletar o m\u00e1ximo poss\u00edvel de ideias. Nas pr\u00f3ximas etapas da descoberta, iremos refin\u00e1-las e prioriz\u00e1-las. </p> <p> Acima est\u00e1 ilustrado o nosso quadro de Brainstorming </p>"},{"location":"Produto/brainstorming/#tabela-de-versionamento","title":"Tabela de Versionamento","text":"Data Vers\u00e3o Descri\u00e7\u00e3o Autor(es) 15/05/2023 1.0 Cria\u00e7\u00e3o do documento Vitor Lameir\u00e3o"},{"location":"Produto/contexto_mercado/","title":"Contexto do Mercado","text":""},{"location":"Produto/contexto_mercado/#mercado-de-commodities","title":"Mercado de Commodities","text":""},{"location":"Produto/contexto_mercado/#o-que-sao-commodities","title":"O que s\u00e3o commodities","text":"<p>Primeiramente, antes de entrar a fundo no mercado de commodities, vamos explicar o que s\u00e3o commodities.  Tamb\u00e9m conhecidas como \"mater\u00eda-prima\", as commodities, s\u00e3o produtos b\u00e1sicos e gen\u00e9ricos que s\u00e3o produzidos em grande quantidade e comercializados em mercados globais. Eles geralmente se referem a mat\u00e9rias-primas naturais ou agr\u00edcolas que s\u00e3o extra\u00eddas ou cultivadas, como petr\u00f3leo, g\u00e1s natural, ouro, prata, trigo, milho, soja, caf\u00e9, a\u00e7\u00facar, entre outros.</p>"},{"location":"Produto/contexto_mercado/#importancia-das-commodities-para-o-brasil","title":"Import\u00e2ncia das commodities para o Brasil","text":"<p>O mercado de commodities t\u00eam grande import\u00e2ncia para todas as escalas economicas do pa\u00eds.  Segundos dados do Minist\u00e9rio da Economia, no ano de 2022, o Brasil gerou US$ 334 Bilh\u00f5es a partir de exporta\u00e7\u00f5es das commodities. Esse valor gerado representa um total de 17% de todo o PIB nacional daquele ano.  Al\u00e9m de todo esse impacto ec\u00f4nomico, o mercado de commodities geram, diretamente e indiretamente, milh\u00f5es de empregos para a popula\u00e7\u00e3o brasileira.  Por isso \u00e9 vital que todo esse ecossistema seja apoiado por org\u00e3os governamentais, iniciativas privadas, etc...</p>"},{"location":"Produto/contexto_mercado/#mercado-de-commodities-agricolas","title":"Mercado de commodities agr\u00edcolas","text":""},{"location":"Produto/contexto_mercado/#o-que-sao-commodities-agricolas","title":"O que s\u00e3o commodities agr\u00edcolas","text":"<p>Commodities agr\u00edcolas s\u00e3o produtos b\u00e1sicos, geralmente produzidos em grandes quantidades e comercializados em escala global. Eles s\u00e3o cultivados em fazendas e incluem produtos como:</p> <ul> <li>Soja</li> <li>Trigo</li> <li>Caf\u00e9</li> <li>Milho</li> <li>Entre outros.</li> </ul>"},{"location":"Produto/contexto_mercado/#importancia-das-commodities-agricolas","title":"Import\u00e2ncia das commodities agr\u00edcolas","text":"<p>Dentre os US$ 334 Bilh\u00f5es faturados a partir da exporta\u00e7\u00e3o de commodities, 48% de todo esse valor foram advindos das commodities agr\u00edcolas.  O que revela uma grande relev\u00e2ncia e import\u00e2ncia do agroneg\u00f3cio para toda a economia do pa\u00eds.</p>"},{"location":"Produto/contexto_mercado/#mercado-da-soja","title":"Mercado da soja","text":""},{"location":"Produto/contexto_mercado/#contexto-geral-do-mercado-da-soja","title":"Contexto geral do mercado da soja","text":"<p>O mercado da soja \u00e9 de extrema import\u00e2ncia para a economia brasileira, sendo um dos principais produtos exportados pelo pa\u00eds. O Brasil \u00e9 atualmente o maior produtor e exportador mundial de soja, com uma produ\u00e7\u00e3o m\u00e9dia de 130 milh\u00f5es de toneladas por ano e, segundo dados da Secret\u00e1ria de Com\u00e9rcio Exterior (SECEX), nosso pa\u00eds faturou US$ 46,69 bilh\u00f5es com a venda dessa commodity em 2022.   A exporta\u00e7\u00e3o da soja representa uma grande parcela das receitas de exporta\u00e7\u00e3o do Brasil, o que faz com que a volatilidade do mercado da soja tenha um impacto significativo na economia do pa\u00eds. </p>"},{"location":"Produto/contexto_mercado/#dificuldades-e-problemas-encontrados-no-mercado","title":"Dificuldades e problemas encontrados no mercado","text":"<p>A volatibidade do mercado pode afetar diretamente as opera\u00e7\u00f5es de compra e venda dessa commodity, essa imprevisibilidade pode gerar incertezas e insegura\u00e7as para os dependentes desse mercado quando forem realizar uma opera\u00e7\u00e3o de compra ou venda da soja.  Essa inseguran\u00e7a e incerteza causada no mercado est\u00e1 muito relacionada com not\u00edcias que afetam diretamente o mercado da soja. Informa\u00e7\u00f5es sobre poss\u00edveis condi\u00e7\u00f5es clim\u00e1ticas impr\u00f3prias para o cultivo, aumento dos custos de produ\u00e7\u00e3o, retomada de negocia\u00e7\u00f5es entre pa\u00edses produtores de soja e, at\u00e9 mesmo pandemias, causam um desconforto no mercado e fazem com que as opera\u00e7\u00f5es de compra e venda da commodity tenham mais riscos do que o padr\u00e3o. </p> <p></p> <p> Acima encontra-se dados do CEPEA sobre a varia\u00e7\u00e3o do pre\u00e7o da soja em 3 anos. </p> <p>Como mostrado no gr\u00e1fico, o mercado da soja \u00e9 muito imprevis\u00edvel, principalmente quando analisamos o seu pre\u00e7o de venda, por isso, qualquer ferramenta que apoie as decis\u00f5es de compra e vendas no mercado da soja \u00e9 totalmente \u00fatil e valiosa para as pessoas que realizam essas opera\u00e7\u00f5es.  Nesse sentido que o Radar da Soja surge para auxiliar milhares de pessoas que dependem desse mercado para gerar lucro pessoal e para suas empresas. </p>"},{"location":"Produto/contexto_mercado/#tabela-de-versionamento","title":"Tabela de Versionamento","text":"Data Vers\u00e3o Descri\u00e7\u00e3o Autor(es) 10/05/2023 1.0 Cria\u00e7\u00e3o do documento Vitor Lameir\u00e3o"},{"location":"Produto/personas/","title":"Personas","text":""},{"location":"Produto/personas/#o-que-e-uma-persona","title":"O que \u00e9 uma persona","text":"<p>Persona \u00e9 uma representa\u00e7\u00e3o f\u00edsica de um usu\u00e1rio ideal para um produto ou organiza\u00e7\u00e3o. Essa persona \u00e9 criada com base em pesquisa e an\u00e1lise de dados sobre o p\u00fablico-alvo do neg\u00f3cio. A cria\u00e7\u00e3o desse usu\u00e1rio ideal ajuda os criadores desse produto a entender melhor seus clientes e criar estrat\u00e9gias para desenvolver e adequar o software a atender as necessidades espec\u00edficas desse usu\u00e1rio.</p>"},{"location":"Produto/personas/#nossas-personas","title":"Nossas personas","text":""},{"location":"Produto/personas/#jorge-o-digital-do-agro","title":"Jorge, o digital do Agro","text":"<p> Persona criada utilizando o Figma </p> <p>Acima est\u00e3o detalhadas informa\u00e7\u00f5es sobre a nossa primeira persona e principal cliente em potencial, o Jorge.  Utilizamos todos os dados coletados em nossa pesquisa para homogeneizar, criar e definir um dos poss\u00edveis usu\u00e1rios e clientes do Radar da Soja. Focamos principalmente em seus pontos de dor e objetivos para criar a nossa aplica\u00e7\u00e3o. </p>"},{"location":"Produto/personas/#breno-o-trader","title":"Breno, o Trader","text":"<p> Persona criada utilizando o Figma </p> <p>Acima est\u00e1 detalhado informa\u00e7\u00f5es sobre a nossa segunda persona, o Breno.  Diferentemente do Jorge, que foi criado com base exclusivamente em nossa pesquisa, esta persona foi constru\u00edda ap\u00f3s conversas com pessoas do mercado de Trading de Commodities que demonstraram interesse na ideia do produto. Al\u00e9m disso, tamb\u00e9m utilizamos os dados coletados em nossa pesquisa para complementar as informa\u00e7\u00f5es obtidas nas conversas. </p>"},{"location":"Produto/personas/#pontos-em-comum","title":"Pontos em comum","text":"<p>Ap\u00f3s definirmos as nossas duas personas, percebemos que existem pontos em comum entre elas, mesmo pertencendo a \u00e1reas diferentes dentro do mercado de Soja. </p> <p>Abaixo segue os pontos em comum que foram encontrados e utilizados de guia para o desenvolvimento do Radar da Soja:</p> <ul> <li>Objetivos: Considerando suas \u00e1reas de atua\u00e7\u00e3o, ambos desejam um maior lucro pessoal para suas opera\u00e7\u00f5es;</li> <li>Pontos de Dor: Considerando suas \u00e1reas de atua\u00e7\u00e3o, ambos gastam muito tempo pesquisando sobre o mercado para embasar suas opera\u00e7\u00f5es de compra e venda da Soja e, tamb\u00e9m, os dois sentem falta de uma ferramenta/dados que possa auxilia-los com essas opera\u00e7\u00f5es.</li> </ul>"},{"location":"Produto/personas/#tabela-de-versionamento","title":"Tabela de Versionamento","text":"Data Vers\u00e3o Descri\u00e7\u00e3o Autor(es) 15/05/2023 1.0 Cria\u00e7\u00e3o do documento Vitor Lameir\u00e3o"},{"location":"Produto/prioridade_func/","title":"Prioridade de Funcionalidades","text":"<p>Ap\u00f3s realizarmos a fase de Brainstorming de Funcionalidades, seguimos para a pr\u00f3xima etapa de descoberta do Radar da Soja. Nesta etapa, priorizamos e definimos quais funcionalidades idealizadas far\u00e3o parte do nosso produto utilizando duas t\u00e9cnicas amplamente utilizadas no mercado: Matriz MoSCoW e Matriz de Esfor\u00e7o e Impacto.</p>"},{"location":"Produto/prioridade_func/#matriz-moscow","title":"Matriz MoSCoW","text":"<p>A Matriz MoSCoW \u00e9 uma ferramenta utilizada para ajudar a priorizar as funcionalidades de um produto. A matriz divide os requisitos/funcionalidades em quatro categorias principais: Must Have (deve ter), Should Have (deveria ter), Could Have (poderia ter) e Won't Have (n\u00e3o ter\u00e1). </p> <ul> <li>Must Have: s\u00e3o essenciais para o sucesso do projeto e devem ser implementados;</li> <li>Should Have: s\u00e3o importantes, mas n\u00e3o cr\u00edticos, e podem ser adiados se necess\u00e1rio;</li> <li>Could Have: s\u00e3o desej\u00e1veis, mas n\u00e3o s\u00e3o essenciais, e podem ser descartados ou adiados sem afetar significativamente o sucesso do projeto;</li> <li>Won't Have:  s\u00e3o aqueles que n\u00e3o ser\u00e3o inclu\u00eddos no produto atual. </li> </ul> <p>Abaixo est\u00e1 detalhado a nossa Matriz MoSCoW de prioriza\u00e7\u00e3o.</p> <p> Quadro criado utilizando o Miro </p>"},{"location":"Produto/prioridade_func/#matriz-de-esforco-e-impacto","title":"Matriz de Esfor\u00e7o e Impacto","text":"<p>A matriz de esfor\u00e7o e impacto \u00e9 uma ferramenta usada para avaliar as funcionalidades de um produto e classific\u00e1-las com base em dois crit\u00e9rios principais: o esfor\u00e7o necess\u00e1rio para desenvolve-lo e o impacto que ela ter\u00e1 no produto.</p> <p>O esfor\u00e7o \u00e9 medido pela quantidade de tempo, recursos e pessoal necess\u00e1rio para desenvolver a funcionalidade e o impacto \u00e9 medido pela import\u00e2ncia da funcionalidade para o sucesso geral do produto.</p> <p>A matriz de esfor\u00e7o e impacto \u00e9 geralmente apresentada como uma matriz de duas dimens\u00f5es, com o esfor\u00e7o representado no eixo horizontal e o impacto no eixo vertical. As funcionalidades s\u00e3o ent\u00e3o classificadas em quatro categorias principais:</p> <ul> <li>Alto esfor\u00e7o, alto impacto: funcionalidades cr\u00edticas que exigem muitos recursos e t\u00eam um grande impacto no produto;</li> <li>Baixo esfor\u00e7o, alto impacto: funcionalidades importantes, mas relativamente f\u00e1ceis de executar;</li> <li>Alto esfor\u00e7o, baixo impacto: funcionalidades secund\u00e1rias que podem ser adiadas ou eliminadas se necess\u00e1rio;</li> <li>Baixo esfor\u00e7o, baixo impacto: funcionalidades triviais que n\u00e3o s\u00e3o essenciais para o sucesso do produto.</li> </ul> <p>Abaixo est\u00e1 detalhado a nossa Matriz de Esfor\u00e7o e Impacto de prioriza\u00e7\u00e3o.</p> <p> Quadro criado utilizando o Miro </p>"},{"location":"Produto/prioridade_func/#tabela-de-versionamento","title":"Tabela de Versionamento","text":"Data Vers\u00e3o Descri\u00e7\u00e3o Autor(es) 19/05/2023 1.0 Cria\u00e7\u00e3o do documento Vitor Lameir\u00e3o"},{"location":"Produto/roadmap_prod/","title":"Roadmap do Produto","text":"<p>Ap\u00f3s conclus\u00e3o do processo inicial de descoberta do Radar da Soja, obtivemos informa\u00e7\u00f5es suficientes para criar um Roadmap detalhado das atividades de cada uma das Stacks de desenvolvimento.</p> <p>Para cria\u00e7\u00e3o desse roadmap, utilizamos as tarefas que foram criadas no GitHub Projects e analisamos todo nosso processo de desenvolvimento que ser\u00e1 desenvolvido at\u00e9 o final do programa &lt;/pantanal.dev&gt;.</p> <p>Abaixo est\u00e1 detalhado o nosso Roadmap do Produto, onde est\u00e3o separados atividades em 3 frentes:</p> <ul> <li>Upstream: Time respons\u00e1vel pela investiga\u00e7\u00e3o de mercado, a identifica\u00e7\u00e3o de oportunidades, a defini\u00e7\u00e3o de requisitos e especifica\u00e7\u00f5es do produto e a an\u00e1lise de concorrentes;</li> <li>Product Development: Time respons\u00e1vel pelo desenvolvimento da solu\u00e7\u00e3o idealizada;</li> <li>Infra: Time respons\u00e1vel por toda cria\u00e7\u00e3o e configura\u00e7\u00e3o dos servidores, bancos de dados e outros componentes de software e nuvem utilizados no projeto.</li> </ul> <p> Quadro criado utilizando o Miro </p>"},{"location":"Produto/roadmap_prod/#tabela-de-versionamento","title":"Tabela de Versionamento","text":"Data Vers\u00e3o Descri\u00e7\u00e3o Autor(es) 19/05/2023 1.0 Cria\u00e7\u00e3o do documento Vitor Lameir\u00e3o"},{"location":"Produto/visao_futuro/","title":"Vis\u00e3o de Futuro","text":"<p>N\u00f3s, da equipe Comitiva Esperan\u00e7a, acreditamos fortemente que o Radar da Soja, um produto criado para participar do programa &lt;/pantanal.dev&gt;, tem grande potencial para se expandir e se tornar rent\u00e1vel para o nosso time.</p> <p>N\u00e3o pretendemos descontinuar esse produto ap\u00f3s a conclus\u00e3o do programa. Por isso, com base em toda a descoberta inicial feita para o Radar da Soja, criamos um Roadmap Futuro para o pr\u00f3ximo semestre.</p> <p>Com esse Roadmap, conseguimos nos planejar e mapear tudo o que precisar\u00e1 ser feito para alcan\u00e7armos nosso objetivo de 6 meses: comercializar o Radar da Soja.</p> <p>Abaixo est\u00e1 detalhado todas as atividades que precisar\u00e3o ser realizadas para alcan\u00e7armos nosso sonho com o Radar da Soja.</p> <p> Quadro criado utilizando o Miro </p>"},{"location":"Produto/visao_futuro/#tabela-de-versionamento","title":"Tabela de Versionamento","text":"Data Vers\u00e3o Descri\u00e7\u00e3o Autor(es) 19/05/2023 1.0 Cria\u00e7\u00e3o do documento Vitor Lameir\u00e3o"},{"location":"Produto/visao_produto/","title":"Vis\u00e3o do Produto","text":"<p>Ao analisarmos os dados coletados em nossas pesquisas de mercado, observamos que h\u00e1 uma grande insatisfa\u00e7\u00e3o dos entrevistados com a imprevisibilidade do mercado da soja, al\u00e9m do impacto negativo de algumas not\u00edcias sobre as opera\u00e7\u00f5es de compra e venda desse produto. Com base nesses insights, a equipe da Comitiva Esperan\u00e7a idealizou um produto que soluciona esses problemas e atende \u00e0s necessidades de Jorge e Breno, nossas personas.</p> <p>Com todas essas informa\u00e7\u00f5es n\u00f3s desenvolvemos uma das etapas do m\u00e9todo de descoberta de produto chamado Lean Inception, que \u00e9 a defini\u00e7\u00e3o da Vis\u00e3o do Produto para que a nossa ideia seja clara e objetiva e, com essa vis\u00e3o inicial e detalhada, possamos guiar todas as funcionalidades do nosso produto para que atendam ess\u00e3o defini\u00e7\u00e3o inicial.</p> <p></p> <p> Acima est\u00e1 ilustrado nosso quadro de Vis\u00e3o do Produto criado na ferramenta MIRO. </p>"},{"location":"Produto/visao_produto/#tabela-de-versionamento","title":"Tabela de Versionamento","text":"Data Vers\u00e3o Descri\u00e7\u00e3o Autor(es) 10/05/2023 1.0 Cria\u00e7\u00e3o do documento Vitor Lameir\u00e3o"}]}