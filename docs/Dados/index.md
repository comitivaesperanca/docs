
# üê±‚Äçüë§ Dados

Com a proposta da solu√ß√£o definida, foi necess√°rio definir a arquitetura da plataforma de dados que ir√° suportar a solu√ß√£o, bem como quais dados, modelos e ferramentas ser√£o utilizados para a constru√ß√£o da solu√ß√£o.

## Fonte de dados

Foi realizado uma busca de dados abertos que pudessem ser utilizados para a constru√ß√£o da solu√ß√£o em sites como [Kaggle](https://kaggle.com), [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php) e [Google Dataset Search](https://datasetsearch.research.google.com/). Entretanto, n√£o foi encontrado nenhum dataset que atendesse aos requisitos necess√°rios para a constru√ß√£o da solu√ß√£o, como por exemplo: dados em portugu√™s, dados de not√≠cias referente a Soja, bem como uma classifica√ß√£o de sentimento para essas not√≠cias que tivesse o ponto de vista do produtor rural/trading.

### CEPEA - Centro de Estudos Avan√ßados em Economia Aplicada

Com a necessidade de treinarmos o modelo utilizando o m√°ximo de fontes que n√£o houvesse vi√©s pol√≠tico, foi encontrado o site do CEPEA, que √© um centro de estudos avan√ßados em economia aplicada, que √© uma institui√ß√£o de pesquisa da USP. O CEPEA possui uma [p√°gina de boletins di√°rios](https://www.cepea.esalq.usp.br/br/categoria/diarias-de-mercado.aspx), chamada Di√°rias do Mercado, que s√£o publica√ß√µes di√°rias sobre o mercado de commodities agr√≠colas, como soja, milho, caf√©, etc. Esses boletins s√£o publicados diariamente desde 1997.

### Not√≠cias Agricolas

Al√©m do CEPEA, foi encontrado o site [Not√≠cias Agricolas](https://www.noticiasagricolas.com.br/), que √© um portal de not√≠cias sobre o agroneg√≥cio brasileiro. Esse portal possui uma se√ß√£o de not√≠cias sobre soja, que s√£o publicadas diariamente desde 2006. Essa fonte de not√≠cias √© interessante pois possui uma vis√£o mais voltada para o produtor rural, diferente do CEPEA que possui uma vis√£o econ√¥mica.
O Not√≠cias Agricolas possui um grande volume de not√≠cias que s√£o de outras fontes como [Reuters](https://www.reuters.com/), o que pode ser interessante para o treinamento do modelo, uma vez que podemos regras para o mercado internacional da commodity.

## Coleta de dados

### Introdu√ß√£o

Para realizar a coleta de dados das plataformas acima, foi necess√°rio a utiliza√ß√£o da ferramenta [Apache Airflow](https://airflow.apache.org/), que √© uma plataforma de orquestra√ß√£o de fluxos de trabalho (workflow) de c√≥digo aberto que permite aos usu√°rios programar, agendar e monitorar tarefas em fluxos de trabalho complexos. Essa ferramenta foi escolhida pois suas vantagens permite com que o processo de coleta seja escal√°vel, flex√≠vel e com monitoramento em tempo real.
As tarefas de coleta de dados foram divididas em 3 etapas:

- [Coleta de dados do CEPEA](https://github.com/comitivaesperanca/data/blob/main/airflow/dags/data_engineering/scrapping_cepea.py)
- [Coleta de dados do Not√≠cias Agricolas](https://github.com/comitivaesperanca/data/blob/main/airflow/dags/data_engineering/scrapping_noticias_agricolas.py)

Para cada fonte de dados, foi necess√°rio criar uma DAG (Directed Acyclic Graph) que √© um fluxo de trabalho que define como as tarefas ser√£o executadas, para cada fonte de dados. Essas DAGs foram criadas utilizando a sintaxe de Python, e utilizam bibliotecas como BeautifulSoup, Pandas e Requests para realizar a coleta de dados.

O processo de fluxo de dados ficou da seguinte forma:

![Fluxo de dados](images/fluxo_de_coleta.png)

### Processo de coleta

Para executar a primeira carga de dados completa, foi necess√°rio parametrizar as DAGs para buscar os dados desde 1997, para o CEPEA, e desde 2006, para o Not√≠cias Agricolas. Ap√≥s a execu√ß√£o da primeira carga de dados, as DAGs foram parametrizadas para buscar os dados apenas do dia anterior, para que o processo de coleta seja incremental.

![DAG desenvolvida para coleta de dados do CEPEA](images/dag_cepea.png "DAG desenvolvida para coleta de dados do CEPEA")
![DAG desenvolvida para coleta de dados do Not√≠cias Agricolas](images/dag_noticias_agricolas.png "DAG desenvolvida para coleta de dados do Not√≠cias Agricolas")

Na imagem acima, √© poss√≠vel visualizar a DAG desenvolvida para a coleta de dados do CEPEA e do Not√≠cias Agricolas. Essas DAGs s√£o executadas diariamente, e a cada execu√ß√£o, os dados do dia anterior s√£o coletados e armazenados localmente, podendo vir a ser carregado a um banco de dados ou a um data lake.

### An√°lise explorat√≥ria
Ao concluir a carga incremental do CEPEA, foi poss√≠vel obter 7639 not√≠cias, desde Julho de 2006 at√© a presente data, conforme o gr√°fico abaixo:
<iframe width=700, height=500 frameBorder=0 src="images/quantidade_noticias_cepea.html"></iframe> 

J√° o Not√≠cias Agricolas, foi poss√≠vel obter 23.601 not√≠cias, conforme a imagem abaixo:
<iframe width=700, height=500 frameBorder=0 src="images/quantidade_noticias_agricolas.html"></iframe> 

Para iniciar o tratamento das not√≠cias, de maneira que fosse poss√≠vel filtrar apenas as not√≠cias referentes a soja, foi necess√°rio realizar uma an√°lise explorat√≥ria dos dados, para entender quantas not√≠cias houvesse Soja mencionada, ao menos duas vezes. No Dataset do CEPEA, foi poss√≠vel encontrar 954 not√≠cias que tivesse a palavra Soja mencionada ao menos duas vezes, conforme a imagem abaixo:
<iframe width=700, height=500 frameBorder=0 src="images/soja.html"></iframe>

No Dataset do Not√≠cias Agricolas, foi poss√≠vel encontrar 3.358 not√≠cias que tivesse a palavra Soja mencionada ao menos duas vezes, conforme a imagem abaixo:
<iframe width=700, height=500 frameBorder=0 src="images/soja_na.html"></iframe>

### Rotula√ß√£o dos dados
Para realizar a rotula√ß√£o dos dados, foi utilizado a ferramenta [Label Studio](https://labelstud.io/), que √© uma plataforma de marca√ß√£o de dados (data labeling) de c√≥digo aberto que permite criar tarefas de marca√ß√£o de forma simples e escal√°vel. 
Conforme o curto prazo para a entrega do projeto, foi necess√°rio realizar a rotula√ß√£o dos dados manualmente, por√©m, para uma entrega futura, √© poss√≠vel utilizar t√©cnicas de NLP para realizar a rotula√ß√£o dos dados de maneira autom√°tica, como por exemplo, utilizando o [Spacy](https://spacy.io/).

Devido ao grande volume, a equipe optou por classificar apenas as not√≠cias do CEPEA, que possu√≠a um volume menor de dados, e que possu√≠a uma vis√£o mais econ√¥mica, diferente do Not√≠cias Agricolas, que pode possuir not√≠cias com vi√©s pol√≠tico.

Foi realizado o deployment da ferramenta Label Studio utilizando o servi√ßo de Kubernetes da [Azure](https://azure.microsoft.com/pt-br/), e a rotula√ß√£o dos dados foi realizada por 4 pessoas do time, conforme a imagem abaixo:
![Rotula√ß√£o dos dados](images/labelstudio_rotulacao.jfif "Momento onde o time atingiu 599 not√≠cias rotuladas")

### Cria√ß√£o do modelo
Ap√≥s a rotula√ß√£o dos dados, foi necess√°rio realizar o treinamento do modelo de Machine Learning, para que fosse poss√≠vel criar o *Motor de Classifica√ß√£o* do Radar da Soja, que √© o respons√°vel por classificar as not√≠cias em Positivo, Neutro ou Negativo. Com a necessidade de desenvolvermos um modelo utilizando BERT (atrav√©s de redes neurais), o time optou por desenvolver um modelo baseline, para servir de efeito de compara√ß√£o, utilizando o modelo [Naive Bayes Multinomial](https://scikit-learn.org/stable/modules/naive_bayes.html), que √© um modelo de classifica√ß√£o probabil√≠stico baseado no teorema de Bayes, que assume que a presen√ßa de uma caracter√≠stica em uma classe n√£o est√° relacionada com a presen√ßa de qualquer outra caracter√≠stica.

#### Modelo Naive Bayes Multinomial (Baseline)
O modelo Naive Bayes Multinomial foi escolhido por ser um modelo de classifica√ß√£o probabil√≠stico, que √© um modelo simples e r√°pido, que pode ser utilizado como baseline para compara√ß√£o com outros modelos mais complexos. <br>
No Naive Bayes Multinomial, determinamos a probabilidade de uma not√≠cia pertencer a uma classe, baseado na frequ√™ncia de palavras que aparecem na not√≠cia.  <br>
Para o treinamento do modelo, foi utilizado o dataset rotulado (421 not√≠cias), sendo separado em 80% para treino (336 not√≠cias) e 20% (101 not√≠cias) para valida√ß√£o.  <br>
Ap√≥s o treinamento, foi poss√≠vel obter o seguinte reporte de classifica√ß√£o:

<figure>
    <img src="images/modelo_naive_treino.png">
    <figcaption>Resultado de classifica√ß√£o do modelo no conjunto de teste. (Fonte: Autores, 2023)</figcaption>
</figure>
    
Enquanto que para o conjunto de valida√ß√£o, foi poss√≠vel obter o seguinte reporte de classifica√ß√£o:
<figure>
    <img src="images/modelo_naive_validacao.png">
    <figcaption>Resultado de classifica√ß√£o do modelo no conjunto de valida√ß√£o. (Fonte: Autores, 2023)</figcaption>
</figure>

Ap√≥s o treinamento do modelo, foi poss√≠vel obter uma acur√°cia de 0.62 no conjunto de teste, e 0.60 no conjunto de valida√ß√£o, o que mostra que o modelo possui uma boa capacidade de generaliza√ß√£o, e que pode ser utilizado como baseline para compara√ß√£o com outros modelos mais complexos.

#### Modelo BERT
Com a crescente utiliza√ß√£o de modelos de Deep Learning para a resolu√ß√£o de problemas de NLP, o time optou por utilizar o modelo BERT, que √© um modelo de Deep Learning desenvolvido pelo Google, que possui uma arquitetura baseada em redes neurais, e que possui um desempenho superior a outros modelos de NLP, como o Naive Bayes Multinomial. <br>
O modelo BERT √© utilizado como um modelo pr√©-treinado, que √© treinado em um grande volume de dados, e que pode ser utilizado para resolver problemas de NLP, como classifica√ß√£o de texto, sumariza√ß√£o de texto, entre outros. <br>
Para a aplica√ß√£o do modelo no projeto, foi necess√°rio realizar o fine-tuning do modelo, que √© o processo de treinar o modelo pr√©-treinado em um conjunto de dados espec√≠fico para o problema que se deseja resolver. <br>
Para o treinamento do modelo, foi utilizado o dataset rotulado (421 not√≠cias), sendo separado em 80% para treino (336 not√≠cias) e 20% (101 not√≠cias) para valida√ß√£o.  <br>
Ap√≥s o treinamento, foi poss√≠vel obter o seguinte reporte de classifica√ß√£o para o conjunto de teste:


<figure>
    <img src="images/treinamento_bert.jpg">
    <figcaption>Resultado de classifica√ß√£o do modelo no conjunto de teste.(Fonte: Autores, 2023)</figcaption>
</figure>

<figure>
    <img src="images/validacao_bert.jpg">
    <figcaption>Resultado de classifica√ß√£o do modelo no conjunto de teste.(Fonte: Autores, 2023)</figcaption>
</figure>

#### Considera√ß√µes sobre o modelo
Ap√≥s o treinamento dos modelos, foi poss√≠vel obter os seguintes resultados:

| Modelo | Acur√°cia no conjunto de teste | Acur√°cia no conjunto de valida√ß√£o | Precis√£o - Valida√ß√£o| Recall - Valida√ß√£o | F1-Score - Valida√ß√£o |
| --- | --- | --- | --- | --- | --- |
| Naive Bayes Multinomial | 0.62 | 0.60 | 0.70 | 0.57 | 0.54 |
| BERT | 0.76 | 0.70 | 0.72 | 0.70 | 0.68 |

Por se tratar de um modelo de Deep Learning, o BERT possui uma acur√°cia superior ao Naive Bayes Multinomial, que √© um modelo de Machine Learning tradicional. <br>
Entretanto, o modelo BERT possui uma precis√£o inferior ao Naive Bayes Multinomial, o que pode ser explicado pela quantidade de dados de treinamento.
Para uma entrega futura, √© necess√°rio que o modelo BERT seja treinado com um volume maior de dados, para que seja poss√≠vel obter uma precis√£o maior, e que possa ser utilizado no Radar da Soja.

Contundo, √© nitido que o modelo BERT possui uma acur√°cia superior ao Naive Bayes Multinomial, o que mostra que o modelo BERT possui uma capacidade de generaliza√ß√£o superior ao Naive Bayes Multinomial, e que pode ser utilizado como modelo de classifica√ß√£o no Radar da Soja.

### Deploy do modelo
Para que o modelo possa ser utilizado no Radar da Soja possa ser integrado na plataforma, foi necess√°rio realizar dois deploys do modelo: Integra√ß√£o no Pipeline de ingest√£o de not√≠cias na plataforma e cria√ß√£o de uma API para que seja feito a intera√ß√£o do modelo. O usu√°rio digitaria o texto da not√≠cia e o modelo retornaria a classifica√ß√£o da not√≠cia, com suas respectivas probabilidades.

#### Pipeline de classifica√ß√£o
Para o Pipeline de classifica√ß√£o, foi incrementar a tarefa j√° criada para o Airflow, para que ao concluir a ingest√£o de not√≠cias ao armazenamento, o modelo fosse executado, e que a classifica√ß√£o encaminhada a plataforma atrav√©s da aplica√ß√£o Backend. Para atingir esse objetivo, foi necess√°rio incluir os arquivos dos modelos (Para o Naive Bayes Multinomial, foi necess√°rio incluir o arquivo `naive_bayes.pkl`, e para o BERT, foi necess√°rio incluir os arquivos `modelo_soja_rede_neural.pt`).

#### API de classifica√ß√£o
Para que outras aplica√ß√µes do Radar da Soja pudesse interagir com o modelo, foi necess√°rio criar uma API para que fosse poss√≠vel realizar a classifica√ß√£o de not√≠cias. Para isso, foi necess√°rio criar uma API utilizando a ferramenta [FastAPI](https://fastapi.tiangolo.com/), que √© uma ferramenta de desenvolvimento de APIs de alto desempenho, que utiliza a sintaxe de Python, e que possui uma documenta√ß√£o autom√°tica atrav√©s do Swagger. <br>
Para a cria√ß√£o da API, foi necess√°rio criar um endpoint que recebesse o texto da not√≠cia, e que retornasse a classifica√ß√£o da not√≠cia, com suas respectivas probabilidades, foi necess√°rio carregar o modelo treinado, e que fosse poss√≠vel realizar a classifica√ß√£o da not√≠cia. <br>